variables:
  PYPA_IMAGE_BASE: registry.ddbuild.io/images/mirror/pypa
  PYPA_IMAGE_TAG: 2025-04-12-5990e2d
  PYPA_DEFAULT_IMAGE: "${PYPA_IMAGE_BASE}/manylinux2014_x86_64:${PYPA_IMAGE_TAG}"

compute_library_version:
  image: registry.ddbuild.io/images/dd-octo-sts-ci-base:2025.06-1
  tags: [ "arch:amd64" ]
  stage: package
  id_tokens:
    DDOCTOSTS_ID_TOKEN:
      aud: dd-octo-sts
  script: |
    if [ -z ${GH_TOKEN} ]
    then
      # Use dd-octo-sts to get GitHub token
      dd-octo-sts token --scope DataDog/dd-trace-py --policy gitlab.github-access.read > token
      gh auth login --with-token < token
      rm token
    fi
    # Prevent git operation errors:
    #   failed to determine base repo: failed to run git: fatal: detected dubious ownership in repository at ...
    git config --global --add safe.directory "${CI_PROJECT_DIR}"
    .gitlab/download-library-version-from-gh-actions.sh

    echo "SETUPTOOLS_SCM_PRETEND_VERSION_FOR_DDTRACE=$(cat library-version/version.txt)" | tee library_version.env
    echo "DDTRACE_VERSION=$(cat library-version/version.txt)" | tee -a library_version.env
  artifacts:
    reports:
      dotenv: library_version.env
    paths:
      - "library-version/version.txt"

download_ddtrace_artifacts:
  image: registry.ddbuild.io/images/dd-octo-sts-ci-base:2025.06-1
  tags: [ "arch:amd64" ]
  stage: package
  id_tokens:
    DDOCTOSTS_ID_TOKEN:
      aud: dd-octo-sts
  script: |
    if [ -z ${GH_TOKEN} ]
    then
      # Use dd-octo-sts to get GitHub token
      dd-octo-sts token --scope DataDog/dd-trace-py --policy gitlab.github-access.read > token
      gh auth login --with-token < token
      rm token
    fi
    # Prevent git operation errors:
    #   failed to determine base repo: failed to run git: fatal: detected dubious ownership in repository at ...
    git config --global --add safe.directory "${CI_PROJECT_DIR}"
    .gitlab/download-wheels-from-gh-actions.sh
  artifacts:
    paths:
      - "pywheels/*.whl"
      - "pywheels/*.tar.gz"

download_dependency_wheels:
  image: registry.ddbuild.io/images/mirror/python:$PYTHON_IMAGE_TAG
  tags: [ "arch:amd64" ]
  stage: package
  needs: [ download_ddtrace_artifacts ]
  variables:
    PIP_CACHE_DIR: "${CI_PROJECT_DIR}/.cache/pip"
  parallel:
    matrix: # The image tags that are mirrored are in: https://github.com/DataDog/images/blob/master/mirror.yaml
      - PYTHON_IMAGE_TAG: "3.8"
        PYTHON_VERSION: "3.8"
      - PYTHON_IMAGE_TAG: "3.9.13"
        PYTHON_VERSION: "3.9"
      - PYTHON_IMAGE_TAG: "3.10.13"
        PYTHON_VERSION: "3.10"
      - PYTHON_IMAGE_TAG: "3.11.6"
        PYTHON_VERSION: "3.11"
      - PYTHON_IMAGE_TAG: "3.12.0"
        PYTHON_VERSION: "3.12"
      - PYTHON_IMAGE_TAG: "3.13.0"
        PYTHON_VERSION: "3.13"
  script:
    - .gitlab/download-dependency-wheels.sh
  cache:
    - key: v0-download-dep-wheels-cache
      paths:
        - ${CI_PROJECT_DIR}/.cache/
  artifacts:
    paths:
      - "pywheels-dep/"


# Build artifacts
.python_tags: &python_tags
  - "cp38-cp38"
  - "cp39-cp39"
  - "cp310-cp310"
  - "cp311-cp311"
  - "cp312-cp312"
  - "cp313-cp313"

.python_versions: &python_versions
  - "3.8"
  - "3.9"
  - "3.10"
  - "3.11"
  - "3.12"
  - "3.13"

.linux_platforms: &linux_platforms
  - "manylinux2014"
  - "musllinux_1_2"

.setup_manylinux_python:
    - |
      # Setup python
      echo -e "\e[0Ksection_start:`date +%s`:setup_python[collapsed=true]\r\e[0KSetup python"
      manylinux-interpreters ensure "${PYTHON_TAG}"
      /opt/python/${PYTHON_TAG}/bin/python -m pip install -U -r ".gitlab/package/requirements.txt"
      /opt/python/${PYTHON_TAG}/bin/python --version
      /opt/python/${PYTHON_TAG}/bin/python -m pip --version
      /opt/python/${PYTHON_TAG}/bin/python -m pip cache info
      /opt/python/${PYTHON_TAG}/bin/python -m pip freeze
      echo -e "\e[0Ksection_end:`date +%s`:setup_python\r\e[0K"

.setup_pip_cache:
  - |
    # Setup pip cache
    echo -e "\e[0Ksection_start:`date +%s`:setup_pip_cache[collapsed=true]\r\e[0KSetup pip cache"
    mkdir -p "${PIP_CACHE_DIR}"
    chown -R "$(id -u):$(id -g)" "${PIP_CACHE_DIR}"
    echo -e "\e[0Ksection_end:`date +%s`:setup_pip_cache\r\e[0K"

.setup_rust:
  - |
    # Setup rust
    echo -e "\e[0Ksection_start:`date +%s`:setup_rust[collapsed=true]\r\e[0KSetup rust"
    if [ "$ARCH" == "i686" ] && [ "$PLATFORM" == "musllinux_1_2" ];
    then
      apk add --no-cache gcc libgcc libstdc++ llvm15-libs musl musl-dev rust-stdlib
      apk add --no-cache rust cargo
    else
      curl https://sh.rustup.rs -sSf | sh -s -- --default-toolchain stable -y
    fi
    export PATH=$CARGO_HOME/bin:$PATH
    rustc --version
    echo -e "\e[0Ksection_end:`date +%s`:setup_rust\r\e[0K"


.build_ddtrace_base:
  stage: package
  needs: [ "compute_library_version" ]
  variables:
    CMAKE_BUILD_PARALLEL_LEVEL: 12
    CARGO_BUILD_JOBS: 12
    SYSTEM_VERSION_COMPAT: 0
    PIP_CACHE_DIR: ${CI_PROJECT_DIR}/.cache/pip
    CARGO_HOME: ${CI_PROJECT_DIR}/.cache/cargo
    PIP_DISABLE_PIP_VERSION_CHECK: 1
  before_script:
    - !reference [ .setup_pip_cache ]
  cache:
    - key: v0-${CI_JOB_NAME_SLUG}-cache
      paths:
        - .cache/
    - key: v0-${CI_JOB_NAME_SLUG}-download-cache
      paths:
        - .download_cache/

.build_ddtrace_linux_base:
  extends: .build_ddtrace_base
  image: ${PYPA_DEFAULT_IMAGE}
  tags: [ "arch:amd64" ]
  timeout: 10m
  variables:
    KUBERNETES_CPU_REQUEST: 6
    KUBERNETES_MEMORY_REQUEST: 4Gi
    KUBERNETES_MEMORY_LIMIT: 8Gi
  before_script:
    - !reference [ .build_ddtrace_base, before_script ]
    - !reference [ .setup_rust ]
    - !reference [ .setup_manylinux_python ]
  cache:
    - !reference [ .build_ddtrace_base, cache ]
    - key: v0-${CI_JOB_NAME_SLUG}-build
      paths:
        - src/native/target/

"build ddtrace sdist":
  extends: .build_ddtrace_base
  image: ${PYPA_DEFAULT_IMAGE}
  tags: [ "arch:amd64" ]
  variables:
    PYTHON_TAG: cp313-cp313
  before_script:
    - !reference [ .build_ddtrace_linux_base, before_script ]
  script:
    - /opt/python/${PYTHON_TAG}/bin/python -m build . --sdist --outdir pywheels/
    - /opt/python/${PYTHON_TAG}/bin/python -m twine check --strict pywheels/*
  artifacts:
    name: ddtrace-sdist
    paths:
      - pywheels/

"build ddtrace linux x86_64":
  extends: .build_ddtrace_linux_base
  image: "${PYPA_IMAGE_BASE}/${PLATFORM}_${ARCH}:${PYPA_IMAGE_TAG}"
  tags: [ "arch:amd64" ]
  parallel:
    matrix:
      - PLATFORM: *linux_platforms
        PYTHON_TAG: *python_tags
  variables:
    ARCH: "x86_64"
  script:
    - |
      # Build the wheel
      echo -e "\e[0Ksection_start:`date +%s`:build_wheel[collapsed=true]\r\e[0KBuild ddtrace wheel"
      echo "pip debug log: ${PIP_LOG}"
      echo "------ DDTRACE STARTING PIP WHEEL BUILD ------" >> "${PIP_LOG}"
      ./.gitlab/package/build_wheel_linux.sh /opt/python/${PYTHON_TAG}/bin/python pywheels/
      echo -e "\e[0Ksection_end:`date +%s`:build_wheel\r\e[0K"
    - |
      #Repair the wheel
      echo -e "\e[0Ksection_start:`date +%s`:repair_wheel[collapsed=true]\r\e[0KRepair ddtrace wheel"
      ./.gitlab/package/repair_wheel_linux.sh pywheels/
      echo -e "\e[0Ksection_end:`date +%s`:repair_wheel\r\e[0K"
    - |
      # Download wheel dependencies (x86_64 and aarch64)
      echo -e "\e[0Ksection_start:`date +%s`:download_wheel_dependencies[collapsed=true]\r\e[0KDownload wheel dependencies"
      if [ "$ARCH" == "x86_64" ] || [ "$ARCH" == "aarch64" ];
      then
        # TODO: Add this
        # .gitlab/download-dependency-wheels.sh "/opt/python/${PYTHON_TAG}/bin/python" "${ARCH}" "${PLATFORM}"
      fi

      # Remove ddtrace from the pip cache so it doesn't get uploaded to the gitlab cache
      /opt/python/${PYTHON_TAG}/bin/python -m pip cache remove ddtrace
      echo -e "\e[0Ksection_end:`date +%s`:download_wheel_dependencies\r\e[0K"
  artifacts:
    name: wheelhouse-${PYTHON_TAG}-${PLATFORM}_${ARCH}
    when: always
    paths:
      - pywheels/
      # TODO: Add this
      # - pywheels-dep/
