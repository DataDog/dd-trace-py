variables:
  IMAGE_BASE_URL: "registry.ddbuild.io/dd-trace-py"
  MANYLINUX_AMD64_IMAGE_TAG: "v85383392-751efc0-manylinux2014_x86_64"

.PYTHON_VERSIONS: &PYTHON_VERSIONS
  - "3.9"
  - "3.10"
  - "3.11"
  - "3.12"
  - "3.13"
  - "3.14"

.PYTHON_TAGS: &PYTHON_TAGS
  - "cp39-cp39"
  - "cp310-cp310"
  - "cp311-cp311"
  - "cp312-cp312"
  - "cp313-cp313"
  - "cp314-cp314"

.AARCH64_IMAGES: &AARCH64_IMAGES
  - "v85383414-751efc0-manylinux2014_aarch64"
  - "v85383359-751efc0-musllinux_1_2_aarch64"

.X86_64_IMAGES: &X86_64_IMAGES
  - "v85383392-751efc0-manylinux2014_x86_64"
  - "v85383325-751efc0-musllinux_1_2_x86_64"

.build_base:
  stage: package
  variables:
    CMAKE_BUILD_PARALLEL_LEVEL: "12"
    CARGO_BUILD_JOBS: "12"
    CMAKE_ARGS: "-DNATIVE_TESTING=OFF"
    # DEV: Hack to make ASM CMake able to find the Python3 library
    CIBW_BUILD: "1"
    # job resource requests
    KUBERNETES_CPU_REQUEST: "6"
    KUBERNETES_MEMORY_REQUEST: "10Gi"
    KUBERNETES_MEMORY_LIMIT: "10Gi"
    DD_DISABLE_VPA: true
  artifacts:
    paths:
      - "pywheels/*.whl"
      - "pywheels/*.tar.gz"
      - "debugwheelhouse/*.log"
      - "debugwheelhouse/*.zip"

.upload_wheels_base:
  tags: ["arch:amd64"]
  image: registry.ddbuild.io/images/mirror/amazon/aws-cli:2.4.29
  stage: package
  variables:
    BUCKET: dd-trace-py-builds

"build sdist":
  extends: .build_base
  image: "${IMAGE_BASE_URL}:${IMAGE_TAG}"
  tags: [ "arch:${ARCH_TAG}" ]
  variables:
    DD_CYTHONIZE: "0"
    ARCH_TAG: "amd64"
    PYTHON_TAG: "cp314-cp314"
    UV_PYTHON: "/opt/python/cp314-cp314/bin/python"
    IMAGE_TAG: "${MANYLINUX_AMD64_IMAGE_TAG}"
  script:
    - .gitlab/scripts/build-sdist.sh

"build linux":
  extends: .build_base
  image: ${IMAGE_BASE_URL}:${IMAGE_TAG}
  tags: [ "arch:$ARCH_TAG" ]
  parallel:
    matrix:
      - ARCH_TAG: "amd64"
        PYTHON_TAG: *PYTHON_TAGS
        IMAGE_TAG: *X86_64_IMAGES
      - ARCH_TAG: "arm64"
        PYTHON_TAG: *PYTHON_TAGS
        IMAGE_TAG: *AARCH64_IMAGES
  script:
    - manylinux-interpreters ensure "${PYTHON_TAG}"
    - |
      if [[ "${UNPIN_DEPENDENCIES:-"false"}" == "true" ]]; then
        manylinux-interpreters ensure "cp314-cp314"  # NB unpinning script requires Py>=311
      fi
    - export UV_PYTHON="/opt/python/${PYTHON_TAG}/bin/python"
    - |
      find src/native -type f -exec touch -t 202401010000 {} \;
      find ddtrace/ -type f -name "*.pyx" -exec touch -t 202401010000 {} \;
      find ddtrace/ -type f -name "*.c" -exec touch -t 202401010000 {} \;
      find ddtrace/ -type f -name "*.cpp" -exec touch -t 202401010000 {} \;
      find ddtrace/ -type f -name "*.h" -exec touch -t 202401010000 {} \;
    - .gitlab/scripts/build-wheel.sh

"build macos":
  extends: .build_base
  tags: [ "macos:sonoma-$ARCH_TAG", "specific:true" ]
  parallel:
    matrix:
      - ARCH_TAG:
          - "amd64"
          - "arm64"
        PYTHON_VERSIONS:
          - "3.9 3.10"
          - "3.11 3.12"
          - "3.13 3.14"
  variables:
    SYSTEM_VERSION_COMPAT: "0"
  script: |
    set -euo pipefail
    for python_version in ${PYTHON_VERSIONS}; do
      echo -e "\e[0Ksection_start:`date +%s`:build_macos_${python_version}\r\e[0KBuilding macOS wheel for Python ${python_version}"

      export UV_PYTHON="${python_version}"
      .gitlab/scripts/build-wheel.sh

      echo -e "\e[0Ksection_end:`date +%s`:build_macos_${python_version}\r\e[0K"
    done

"upload manylinux2014_x86_64":
  extends: .upload_wheels_base
  needs:
    - job: "build linux"
      artifacts: true
      parallel:
        matrix:
          - ARCH_TAG: "amd64"
            PYTHON_TAG: *PYTHON_TAGS
            IMAGE_TAG: "v85383392-751efc0-manylinux2014_x86_64"
    - job: "package version"
  script:
    - .gitlab/scripts/upload-wheels-to-s3.sh "${CI_COMMIT_SHA}" manylinux2014_x86_64
    - .gitlab/scripts/upload-wheels-to-s3.sh "${CI_PIPELINE_ID}" manylinux2014_x86_64

"test sdist":
  image: registry.ddbuild.io/images/mirror/python:3.9.6-alpine3.14
  tags: [ "arch:arm64" ]
  stage: package
  variables:
    CARGO_BUILD_JOBS: "12"
    CMAKE_BUILD_PARALLEL_LEVEL: "12"
    KUBERNETES_CPU_REQUEST: "6"
    KUBERNETES_MEMORY_REQUEST: "10Gi"
    KUBERNETES_MEMORY_LIMIT: "10Gi"
    DD_DISABLE_VPA: true
  needs:
    - job: "build sdist"
      artifacts: true
  script:
    - SDIST_FILE=$(ls ${CI_PROJECT_DIR}/pywheels/*.tar.gz | head -n 1)
    - TMP_DIR=$(mktemp -d) && cd $TMP_DIR
    - |
      apk add curl git gcc g++ musl-dev libffi-dev openssl-dev bash cargo make cmake patchelf
      curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
      export PATH="$HOME/.cargo/bin:$PATH"
      pip install twine readme_renderer[md] "cmarkgfm<2025.10.20"
    - twine check ${SDIST_FILE}
    - pip install ${SDIST_FILE}
    - python ${CI_PROJECT_DIR}/tests/smoke_test.py

"download windows wheels":
  image: registry.ddbuild.io/images/dd-octo-sts-ci-base:2025.06-1
  tags: [ "arch:amd64" ]
  stage: package
  id_tokens:
    DDOCTOSTS_ID_TOKEN:
      aud: dd-octo-sts
  script: |
    if [ -z ${GH_TOKEN} ]
    then
      # Use dd-octo-sts to get GitHub token
      dd-octo-sts token --scope DataDog/dd-trace-py --policy gitlab.github-access.read > token
      gh auth login --with-token < token
      rm token
    fi
    # Prevent git operation errors:
    #   failed to determine base repo: failed to run git: fatal: detected dubious ownership in repository at ...
    git config --global --add safe.directory "${CI_PROJECT_DIR}"
    .gitlab/download-wheels-from-gh-actions.sh
  artifacts:
    paths:
      - "pywheels/*.whl"
      - "pywheels/*.tar.gz"

download_dependency_wheels:
  image: registry.ddbuild.io/images/mirror/python:$PYTHON_IMAGE_TAG
  tags: [ "arch:amd64" ]
  stage: package
  needs:
    - job: "build linux"
      artifacts: true
  variables:
    PIP_CACHE_DIR: "${CI_PROJECT_DIR}/.cache/pip"
  parallel:
    matrix: # The image tags that are mirrored are in: https://github.com/DataDog/images/blob/master/mirror.yaml
      - PYTHON_IMAGE_TAG: "3.9.13"
        PYTHON_VERSION: "3.9"
      - PYTHON_IMAGE_TAG: "3.10.13"
        PYTHON_VERSION: "3.10"
      - PYTHON_IMAGE_TAG: "3.11.6"
        PYTHON_VERSION: "3.11"
      - PYTHON_IMAGE_TAG: "3.12.0"
        PYTHON_VERSION: "3.12"
      - PYTHON_IMAGE_TAG: "3.13.0"
        PYTHON_VERSION: "3.13"
      - PYTHON_IMAGE_TAG: "3.14.0"
        PYTHON_VERSION: "3.14"
  script:
    - .gitlab/download-dependency-wheels.sh
  cache:
    - key: v0-download-dep-wheels-cache
      paths:
        - ${CI_PROJECT_DIR}/.cache/
  artifacts:
    paths:
      - "pywheels-dep/"

"upload all":
  extends: .upload_wheels_base
  needs: [ "ddtrace package", "package version" ]
  script: |
    set -euo pipefail

    # Upload to commit SHA and pipeline ID paths
    .gitlab/scripts/upload-wheels-to-s3.sh "${CI_COMMIT_SHA}"
    .gitlab/scripts/upload-wheels-to-s3.sh "${CI_PIPELINE_ID}"

    # Upload to branch path (only for main/release branches)
    if [ "${CI_COMMIT_BRANCH:-}" = "main" ] || [[ "${CI_COMMIT_BRANCH:-}" =~ ^[0-9]+\.[0-9]+$ ]]; then
      .gitlab/scripts/upload-wheels-to-s3.sh "${CI_COMMIT_BRANCH}"
    fi

# Extract package version from pyproject.toml and save to dotenv artifact
"package version":
  image: registry.ddbuild.io/images/mirror/python:3.14.0
  tags: [ "arch:amd64" ]
  stage: package
  script:
    - PACKAGE_VERSION=$(python -c "import tomllib; print(tomllib.load(open('pyproject.toml', 'rb'))['project']['version'])")
    - echo "PACKAGE_VERSION=${PACKAGE_VERSION}" | tee -a package_version.env
    # Validate commit tag matches version if tag is set
    - |
      if [ -n "${CI_COMMIT_TAG:-}" ]; then
        EXPECTED_TAG="v${PACKAGE_VERSION}"
        if [ "${CI_COMMIT_TAG}" != "${EXPECTED_TAG}" ]; then
          echo "[ERROR] CI_COMMIT_TAG (${CI_COMMIT_TAG}) does not match expected tag (${EXPECTED_TAG})"
          exit 1
        fi
      fi
  artifacts:
    reports:
      dotenv: package_version.env

# Aggregate and validate all built wheels
"ddtrace package":
  image: registry.ddbuild.io/images/mirror/python:3.14.0
  tags: [ "arch:amd64" ]
  stage: package
  needs:
    - "build linux"
    - "build macos"
    - "build sdist"
    - "download windows wheels"
    - "package version"
  script:
    - pip install packaging
    - .gitlab/validate-ddtrace-package.py pywheels
  artifacts:
    paths:
      - "pywheels/*.whl"
      - "pywheels/*.tar.gz"
