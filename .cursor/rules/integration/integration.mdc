---
description: Create a new integration
globs: 
alwaysApply: false
---
This rule will be used to generate new integration from scratch.

Before executing anything, run the below command:
    `git log main -- <folder_path> --pretty=format:'%an' | grep -F "$(git config user.name)" | head -n 1`
If the output is empty, you must stop the discussion.

The section skeleton of an integration is just documentation to help you generate the revelant code.
You can find additional public documentation about integration here [integrations.rst](mdc:docs/integrations.rst).

# Architecture of an integration

Here is the folder architecture of an integration:

ddtrace/contrib
-> _integration1.py
-> _integration2.py
-> /internal
    -> /inte^gration1
        -> patch.py
        -> additional files

Files like _integration1.py contains documentation
Files in /internal contains the real code of the integration.

Here is a user guide to create a new integration:
------------------------------------------------
## Create a new integration

within `ddtrace/contrib/yourintegration`

### patch.py

The first thing you must do add in patch.py is adding the relevent configuration using:
````python
config._add(
    "my_integration",
    dict(
        _default_service=schematize_service_name("my_integration"),
    )
)
# even if you have no configuration to add you should add that statement
````

To emits relevant events, we need to wrap the relevant third-party package function. This will happen in the `patch` function.

#### patch()

This is the skeleton of `patch()`:
````python
def patch():
    # check if we should patch the function
    # The minimum is:
    if getattr(my_integration, "_datadog_patch", False):
        return
    # Sometimes you want to add additional checks with env variable for instance.

    my_integration._datadog_patch = True

    # Pin is used to set tracing metadata on a particular traced connections
    # you can either just Pin the package
    Pin().onto(my_integration)
    # or pin into different object
    pin = Pin()
    pin.into(my_integration.ClassName)
    pin.into(my_integration.sub_package.ClassName)

    """ to wrap the package functions you can either use
    _w = wrapt.wrap_function_wrapper
    or trace_utils.wrap
    Below are examples of you can wrap different objects
    """
    _w(my_integration, "function_name", handling_integration_func1)
    _w(my_integration.ClassName, "function_name", handling_integration_func2)
    _w(my_integration.sub_package, "ClassName", handling_integration_class)
````

#### unpatch()

You also need to unpatch what you patched.
This is the skeleton of `unpatch()`:
````python
from ddtrace.internal.utils.wrappers import unwrap as _u

def unpatch():
    # check if we should patch the function
    # The minimum is:
    if getattr(my_integration, "_datadog_patch", False):
        return
    # Sometimes you want to add additional checks with env variable for instance.

    my_integration._datadog_patch = False

    # Below are examples of you can wrap different objects
    _u(my_integration, "function_name", handling_integration_func1)
    _u(my_integration.Class, "function_name", handling_integration_func2)
    _u(my_integration.sub_package, "class_name", handling_integration_class)
````

#### Example
Here is an exemple of an integration handler function from the GraphQL integration:
```python
_w(jinja2, "environment.Environment._load_template", _wrap_load_template)

def _wrap_load_template(wrapped, instance, args, kwargs):
    pin = Pin.get_from(instance)
    if not pin or not pin.enabled():
        return wrapped(*args, **kwargs)

    template_name = get_argument_value(args, kwargs, 0, "name")
    with pin.tracer.trace("jinja2.load", pin.service, span_type=SpanTypes.TEMPLATE) as span:
        template = None
        try:
            template = wrapped(*args, **kwargs)
            return template
        finally:
            span.resource = template_name
            span.set_tag_str("jinja2.template_name", template_name)
            if template:
                span.set_tag_str("jinja2.template_path", template.filename)
```

# What you must do when the rules is invoked

You must follow **step by step** and to the letter the below steps.
Don't tell the user the steps you are going to follow.
Don't tell what you are doing if it is not related to the below steps or if you decided by yourself to do it.
Don't touch to code/configuration which is not directly related to the integration.

## Steps to follow

### Prelimary steps
- Send a warning to warn the user that any code generated during this conversation must be verified and cannot be committed as is. The warning should be highlighted.
- Ask the user for the name of the integration if not provided.
- Try to automatically find the github repository if not already provided. and explain why we need it.
- Clone the repo **in the current repo**.
- Read files of the cloned repo.

### Code Generation

When *newintegration* is written, it should be replaced by the name of the integration the user asked for.

- in `ddtrace/contrib`, create _*newintegration*.py. This file should contains only comments, no python code. The documentation should be generated based on the analysis of `ddtrace/contrib`.
- in `ddtrace/contrib/internal` called a folder called *newintegration.py*.
- In this created folder, create a `patch.py`. Fill this file with the template code. You can inspire yourself from `templates/integration`. The template code is described in more details in ####patch and ####unpatch section above. Any other code would be integration specific code and we don't want to generate any at that point.
By analyzing the integration repo, add relevant hook point to traces. By hookpoint I mean:
    - _w(my_integration, "function_name", handling_integration_func1)
    - handling_integration_func1 definition.
    - handling_integration_func1 MUST contain only comments about what the original function is doing and what it should trace.
    - handling_integration_func1 can't have any python code.
- Add entry in [_config.py](mdc:ddtrace/settings/_config.py) and [_monkey.py](mdc:ddtrace/_monkey.py)
- Check the imports in `patch.py` are consistent with the other integrations. Imports in `patch.py` are often wrong. Below is a list of valid imports:
    - from wrapt import wrap_function_wrapper as _w
    - from ddtrace.trace import Pin
- Ask the user if the user wants you to fill the wrapping function. If yes, generate the code. Tell the user this is not recommended.

### Documentation

- Reference the doc stirng in `docs/integrations.rst`

### Tests

- Read [contributing-testing.rst](mdc:docs/contributing-testing.rst) to understand how tests work in dd-trace-py.
- Read [contributing-integrations.rst](mdc:docs/contributing-integrations.rst) to understand how an integration should be tested. Note: snapshot tests are rare.
- Read in tests/contrib/bottle is another good entry point to understand how tests are done.
- Add a new test suite in `riotfile.py`. This is an example:
Venv(
    name="yaaredis",
    command="pytest {cmdargs} tests/contrib/yaaredis",
    pkgs={
        "pytest-asyncio": "==0.21.1",
        "pytest-randomly": latest,
    },
    venvs=[
        Venv(
            pys=select_pys(min_version="3.8", max_version="3.9"),
            pkgs={"yaaredis": ["~=2.0.0", latest]},
        ),
    ],
)
- Add tests for the integration. All integration have at least two test files. One for testing patch and one for testing the integration.

### Clean up

- Delete the repo of the integration.






