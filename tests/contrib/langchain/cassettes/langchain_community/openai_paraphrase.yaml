interactions:
- request:
    body: '{"model": "gpt-3.5-turbo-instruct", "prompt": ["Paraphrase this text:\n\n        \n
      Chains allow us to combine multiple\n components together to create a single,
      coherent application.\n For example, we can create a chain that takes user input,
      format it with a PromptTemplate,\n and then passes the formatted response to
      an LLM. We can build more complex chains by combining\n multiple chains together,
      or by\n combining chains with other components.\n \n\n        In the style of
      a a 90s rapper.\n\n        Paraphrase: "], "frequency_penalty": 0, "logit_bias":
      {}, "logprobs": null, "max_tokens": 256, "n": 1, "presence_penalty": 0, "seed":
      null, "temperature": 0.7, "top_p": 1}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '679'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.37.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.37.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.10.5
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    content: "{\n  \"id\": \"cmpl-9pS5lqV3dl9M3x8ynHbf2mCHTQcDh\",\n  \"object\":
      \"text_completion\",\n  \"created\": 1722049741,\n  \"model\": \"gpt-3.5-turbo-instruct\",\n
      \ \"choices\": [\n    {\n      \"text\": \"\\nYo, with chains we can link up
      different parts\\nMake one dope app, ain't gotta stress or start\\nJust take
      user input, use a fly PromptTemplate\\nThen send it to an LLM, yeah it's great\\nAnd
      we ain't done, can build chains on chains\\nMix it up with other components,
      no reins\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\":
      \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 96,\n    \"completion_tokens\":
      69,\n    \"total_tokens\": 165\n  }\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8a996da18b060f41-EWR
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sat, 27 Jul 2024 03:09:02 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=5OznTIwoKYyhFhNfEeyi7DkMRp31cTru4.JbO1vMvSI-1722049742-1.0.1.1-L9eoJf_geVwKEWcZ8_oAUZ7CjNQDDZ1XinQTrgbtrYVv1r1j7y2KCQPZJvcRwa.LRYUbU8.lcSju1BLA2YyoWg;
        path=/; expires=Sat, 27-Jul-24 03:39:02 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=eL2Kx5nW.Z5Y5dijBh.8JMG6y8Jq95yNIpKRNLJziFw-1722049742035-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-3.5-turbo-instruct
      openai-organization:
      - datadog-4
      openai-processing-ms:
      - '810'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '3500'
      x-ratelimit-limit-tokens:
      - '90000'
      x-ratelimit-remaining-requests:
      - '3499'
      x-ratelimit-remaining-tokens:
      - '89629'
      x-ratelimit-reset-requests:
      - 17ms
      x-ratelimit-reset-tokens:
      - 246ms
      x-request-id:
      - req_fe40effea30a9599d675125559c2677a
    http_version: HTTP/1.1
    status_code: 200
version: 1
