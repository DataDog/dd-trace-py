[[
  {
    "name": "langchain.request",
    "service": "",
    "resource": "langchain.llms.openai.OpenAI",
    "trace_id": 0,
    "span_id": 1,
    "parent_id": 0,
    "type": "",
    "error": 1,
    "meta": {
      "_dd.p.dm": "-0",
      "error.message": "Invalid token in prompt: 123456. Minimum value is 0, maximum value is 50280 (inclusive).",
      "error.stack": "Traceback (most recent call last):\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/ddtrace/contrib/langchain/patch.py\", line 159, in traced_llm_generate\n    completions = func(*args, **kwargs)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105_mock_pytest_pytest-mock_coverage_pytest-cov_opentracing_hypothesis6451_langchain_openai_vcrpy_pytest-asyncio_pinecone-client/lib/python3.10/site-packages/langchain/llms/base.py\", line 227, in generate\n    output = self._generate_helper(\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105_mock_pytest_pytest-mock_coverage_pytest-cov_opentracing_hypothesis6451_langchain_openai_vcrpy_pytest-asyncio_pinecone-client/lib/python3.10/site-packages/langchain/llms/base.py\", line 178, in _generate_helper\n    raise e\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105_mock_pytest_pytest-mock_coverage_pytest-cov_opentracing_hypothesis6451_langchain_openai_vcrpy_pytest-asyncio_pinecone-client/lib/python3.10/site-packages/langchain/llms/base.py\", line 165, in _generate_helper\n    self._generate(\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105_mock_pytest_pytest-mock_coverage_pytest-cov_opentracing_hypothesis6451_langchain_openai_vcrpy_pytest-asyncio_pinecone-client/lib/python3.10/site-packages/langchain/llms/openai.py\", line 326, in _generate\n    response = completion_with_retry(self, prompt=_prompts, **params)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105_mock_pytest_pytest-mock_coverage_pytest-cov_opentracing_hypothesis6451_langchain_openai_vcrpy_pytest-asyncio_pinecone-client/lib/python3.10/site-packages/langchain/llms/openai.py\", line 106, in completion_with_retry\n    return _completion_with_retry(**kwargs)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n    return self(f, *args, **kw)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/tenacity/__init__.py\", line 379, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n  File \"/Users/yun.kim/.pyenv/versions/3.10.5/lib/python3.10/concurrent/futures/_base.py\", line 439, in result\n    return self.__get_result()\n  File \"/Users/yun.kim/.pyenv/versions/3.10.5/lib/python3.10/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/tenacity/__init__.py\", line 382, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105_mock_pytest_pytest-mock_coverage_pytest-cov_opentracing_hypothesis6451_langchain_openai_vcrpy_pytest-asyncio_pinecone-client/lib/python3.10/site-packages/langchain/llms/openai.py\", line 104, in _completion_with_retry\n    return llm.client.create(**kwargs)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/openai/api_resources/completion.py\", line 25, in create\n    return super().create(*args, **kwargs)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n    response, _, api_key = requestor.request(\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n    resp, got_stream = self._interpret_response(result, stream)\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n    self._interpret_response_line(\n  File \"/Users/yun.kim/go/src/github.com/DataDog/dd-trace-py/.riot/venv_py3105/lib/python3.10/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n    raise self.handle_error_response(\nopenai.error.InvalidRequestError: Invalid token in prompt: 123456. Minimum value is 0, maximum value is 50280 (inclusive).\n",
      "error.type": "openai.error.InvalidRequestError",
      "langchain.request.api_key": "...key>",
      "langchain.request.model": "text-davinci-003",
      "langchain.request.openai.parameters.frequency_penalty": "0",
      "langchain.request.openai.parameters.max_tokens": "256",
      "langchain.request.openai.parameters.model_name": "text-davinci-003",
      "langchain.request.openai.parameters.n": "1",
      "langchain.request.openai.parameters.presence_penalty": "0",
      "langchain.request.openai.parameters.request_timeout": "None",
      "langchain.request.openai.parameters.temperature": "0.7",
      "langchain.request.openai.parameters.top_p": "1",
      "langchain.request.prompts.0": "12345",
      "langchain.request.prompts.1": "123456",
      "langchain.request.provider": "openai",
      "langchain.request.type": "llm",
      "language": "python",
      "runtime-id": "fee8e436b6394c02893eb6af74d2ada2"
    },
    "metrics": {
      "_dd.agent_psr": 1.0,
      "_dd.measured": 1,
      "_dd.top_level": 1,
      "_dd.tracer_kr": 1.0,
      "_sampling_priority_v1": 1,
      "process_id": 98111
    },
    "duration": 3867000,
    "start": 1688048579097701000
  }]]
