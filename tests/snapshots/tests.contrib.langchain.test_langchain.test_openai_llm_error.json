[[
  {
    "name": "langchain.request",
    "service": "tests.contrib.langchain",
    "resource": "langchain_openai.llms.base.OpenAI",
    "trace_id": 0,
    "span_id": 1,
    "parent_id": 0,
    "type": "",
    "error": 1,
    "meta": {
      "_dd.p.dm": "-0",
      "_dd.p.tid": "67ab7c9200000000",
      "error.message": "Error code: 400 - {'error': {'message': 'Invalid token in prompt: 123. Minimum value is 0, maximum value is 100257 (inclusive).', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "error.stack": "Traceback (most recent call last):\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/ddtrace/contrib/internal/langchain/patch.py\", line 194, in traced_llm_generate\n    completions = func(*args, **kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 803, in generate\n    output = self._generate_helper(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 670, in _generate_helper\n    raise e\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 657, in _generate_helper\n    self._generate(\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/langchain_openai/llms/base.py\", line 350, in _generate\n    response = self.client.create(prompt=_prompts, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/openai/resources/completions.py\", line 539, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"/Users/kyle.verhoog/dev/dd-trace-py/.riot/venv_py3128_c102664954e2741/lib/python3.12/site-packages/openai/_base_client.py\", line 1064, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Invalid token in prompt: 123. Minimum value is 0, maximum value is 100257 (inclusive).', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "error.type": "openai.BadRequestError",
      "langchain.request.api_key": "...key>",
      "langchain.request.model": "gpt-3.5-turbo-instruct",
      "langchain.request.openai.parameters.frequency_penalty": "0",
      "langchain.request.openai.parameters.max_tokens": "256",
      "langchain.request.openai.parameters.model_name": "gpt-3.5-turbo-instruct",
      "langchain.request.openai.parameters.n": "1",
      "langchain.request.openai.parameters.presence_penalty": "0",
      "langchain.request.openai.parameters.temperature": "0.7",
      "langchain.request.openai.parameters.top_p": "1",
      "langchain.request.prompts.0": "12345",
      "langchain.request.prompts.1": "123456",
      "langchain.request.provider": "openai",
      "langchain.request.type": "llm",
      "language": "python",
      "runtime-id": "785abff131a64c6f8e16f99f5fc1ee33"
    },
    "metrics": {
      "_dd.measured": 1,
      "_dd.top_level": 1,
      "_dd.tracer_kr": 1.0,
      "_sampling_priority_v1": 1,
      "process_id": 41221
    },
    "duration": 28472000,
    "start": 1739291794401895000
  }]]
