import itertools
import json
import os
import re
import sys
from typing import Any
from typing import Dict
from typing import List
from typing import Union
import uuid

import pytest
import vcr

import ddtrace.llmobs.experimentation as dne
from ddtrace.llmobs.experimentation._dataset import API_PROCESSING_TIME_SLEEP
from ddtrace.llmobs.experimentation._dataset import DEFAULT_CHUNK_SIZE
from ddtrace.llmobs.experimentation._dataset import MAX_DATASET_ROWS
from ddtrace.llmobs.experimentation._dataset import Dataset
from ddtrace.llmobs.experimentation._dataset import _validate_init
from ddtrace.llmobs.experimentation.utils import _http
from ddtrace.llmobs.experimentation.utils._exceptions import DatasetFileError


# Hardcoded credentials for VCR playback (replace if needed for recording)
DD_APPLICATION_KEY="replace-when-recording"
DD_API_KEY="replace-when-recording"
DD_SITE="us3.datadoghq.com"

# --- Helper Functions ---

def assert_dataset_synced(dataset, expected_len: int, expected_version: int):
    """Asserts dataset is synced with expected length and version."""
    assert len(dataset) == expected_len
    assert dataset._datadog_dataset_id is not None
    assert dataset._datadog_dataset_version == expected_version
    assert dataset._synced is True
    assert not any(dataset._changes.values()), "Changes should be cleared after sync"
    if expected_len > 0:
         # Check if record_ids were populated after sync (if data exists)
         assert "record_id" in dataset._data[0], "record_id should be present after sync"


def assert_dataset_local(dataset, expected_len: int):
    """Asserts dataset is local-only with expected length."""
    assert len(dataset) == expected_len
    assert dataset._datadog_dataset_id is None
    assert dataset._datadog_dataset_version == 0
    assert dataset._synced is True # A new local dataset is considered 'synced' with its local state initially
    assert not any(dataset._changes.values())


def assert_dataset_unsynced(dataset, expected_len: int, expected_version: int, added=0, deleted=0, updated=0):
    """Asserts dataset is unsynced with pending changes."""
    assert len(dataset) == expected_len
    assert dataset._synced is False
    # ID and version should reflect the state *before* changes
    # Only assert ID is not None if it was previously synced (version > 0)
    if expected_version > 0:
        assert dataset._datadog_dataset_id is not None
    else:
        # If version is 0, it could be a new local dataset, ID should be None
        assert dataset._datadog_dataset_id is None
    assert dataset._datadog_dataset_version == expected_version
    assert len(dataset._changes['added']) == added
    assert len(dataset._changes['deleted']) == deleted
    assert len(dataset._changes['updated']) == updated


def scrub_response_headers(response):
    headers_to_remove = ["content-security-policy", "strict-transport-security", "set-cookie"]
    for header in headers_to_remove:
        response["headers"].pop(header, None)
    response["headers"]["content-length"] = ["100"] # Mock content length for VCR consistency
    return response


@pytest.fixture(scope="module")
def experiments_vcr():
    return vcr.VCR(
        cassette_library_dir=os.path.join(os.path.dirname(__file__), "experiments_cassettes"),
        record_mode="all",  # Change to 'all' or 'new_episodes' for recording
        match_on=["path", "method", "body"], # Match on body needed for push/batch update endpoints
        filter_headers=["DD-API-KEY", "DD-APPLICATION-KEY", "Openai-Api-Key", "Authorization"],
        before_record_response=scrub_response_headers,
        # Ignore localhost requests if other instrumentations are active
        ignore_localhost=True,
    )


@pytest.fixture(scope="module", autouse=True)
def init_llmobs(experiments_vcr): # VCR fixture ensures cassette context is available if needed
    """Initializes the LLMObs experimentation module once per test file."""
    # VCR filtering specified in the experiments_vcr fixture handles redacting keys
    # if they appear in actual HTTP requests made *within* tests.
    # Use the provided hardcoded keys directly for init.
    api_key = DD_API_KEY
    app_key = DD_APPLICATION_KEY

    try:
        dne.init(
            ml_app="test-app", # Provide the required ML application name
            project_name="Testing Project",
            api_key=api_key,
            application_key=app_key,
            site=DD_SITE
        )
    except Exception as e:
        pytest.skip(f"Skipping LLMObs tests: Initialization failed - {e}")

# --- Test Data Fixtures ---

@pytest.fixture
def sample_data_simple():
    """Basic list of string input/output."""
    return [
        {"input": "What is 1+1?", "expected_output": "2"},
        {"input": "Capital of UK?", "expected_output": "London"},
    ]

@pytest.fixture
def sample_data_dict():
    """List of dict input/output."""
    return [
        {"input": {"prompt": "capital of France?"}, "expected_output": {"response": "Paris"}},
        {"input": {"prompt": "capital of Germany?"}, "expected_output": {"response": "Berlin"}},
    ]

@pytest.fixture
def sample_data_mixed():
    """Mixed string/dict data with metadata. Keys are consistent across rows."""
    return [
        {"input": "2+2?", "expected_output": "4", "category": "math", "difficulty": 1},
        {"input": {"prompt": "Largest Planet?"}, "expected_output": {"answer": "Jupiter"}, "category": "space", "difficulty": None},
    ]

@pytest.fixture
def sample_data_diverse():
    """Data with mixed types: str, int, float, bool, None, list, nested dict."""
    return [
        {
            "input": {"prompt": "Analyze sentiment", "text": "I love this product!"},
            "expected_output": {"sentiment": "positive", "score": 0.95},
            "metadata": {"model_id": "sentiment-v1.2", "req_id": 1001, "is_valid": True, "params": None}
        },
        {
            "input": {"prompt": "Extract entities", "text": "Alice went to Paris"},
            "expected_output": {"entities": [{"name": "Alice", "type": "PERSON"}, {"name": "Paris", "type": "LOCATION"}], "score": None},
            "metadata": {"model_id": "ner-v3.0", "req_id": 1002, "is_valid": True, "params": {"threshold": 0.7}}
        },
        {
            "input": {"prompt": "Translate", "text": "Hello"},
            "expected_output": {"translation": "Bonjour", "language": "fr"},
            "metadata": {"model_id": "translate-en-fr", "req_id": 1003, "is_valid": False, "params": {"temperature": 0.5}}
        },
    ]

@pytest.fixture
def local_dataset_simple(sample_data_simple):
    """Dataset instance with simple local data."""
    return dne.Dataset(name="test-local-simple", data=sample_data_simple, description="Simple math/geo")

@pytest.fixture
def local_dataset_dict(sample_data_dict):
    """Dataset instance with dict local data."""
    return dne.Dataset(name="test-local-dict", data=sample_data_dict, description="Dict questions")

@pytest.fixture
def local_dataset_mixed(sample_data_mixed):
    """Dataset instance with mixed local data and metadata."""
    return dne.Dataset(name="test-local-mixed", data=sample_data_mixed, description="Mixed types")

@pytest.fixture
def local_dataset_diverse(sample_data_diverse):
    """Dataset instance with diverse local data."""
    return dne.Dataset(name="test-local-diverse", data=sample_data_diverse, description="Diverse types")

@pytest.fixture(scope="module")
def meals_workouts_data():
    """Provides the raw data for the meals and workouts dataset."""
    return [
        # --- Note: Formatting input/output/metadata structure ---
        {
            "input": {"prompt": "1 medium size pizza"},
            "expected_output": {"response": [{"type": "meal", "description": "1 medium size pizza", "calories": 2300, "protein": 20, "carbs": 20, "fat": 20}]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "30 minutes of yoga"},
            "expected_output": {"response": [{"type": "workout", "description": "30 minutes of yoga", "exercise": "yoga", "duration_seconds": 1800}]},
            "metadata": {"category": "exercise"}
        },
        {
            "input": {"prompt": "1 hour of yoga"},
            "expected_output": {"response": [{"type": "workout", "description": "1 hour of yoga", "exercise": "yoga", "duration_seconds": 3600}]},
            "metadata": {"category": "exercise"}
        },
        {
            "input": {"prompt": "3x10 bench press 225lbs"},
            "expected_output": {"response": [{"type": "workout", "description": "3x10 bench press 225lbs", "exercise": "bench press", "series": 3, "reps": 10, "weight_kg": 102}]}, # Corrected weight to kg
            "metadata": {"category": "exercise", "intensity": "high"}
        },
        {
            "input": {"prompt": "1000 calories"},
            "expected_output": {"response": [{"type": "meal", "description": "1000 calories", "calories": 1000, "protein": 0, "carbs": 0, "fat": 0}]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "Feeling hungry"},
            "expected_output": {"response": {"type": "error"}},
            "metadata": {"category": "unknown"}
        },
        {
            "input": {"prompt": "5 tacos and a coke"},
            "expected_output": {"response": [
                {"type": "meal", "description": "5 tacos", "calories": 1000, "protein": 100, "carbs": 100, "fat": 100},
                {"type": "meal", "description": "a coke", "calories": 100, "protein": 0, "carbs": 0, "fat": 0}
            ]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "I ran 5km and then ate 3 hard boiled eggs"},
            "expected_output": {"response": [
                {"type": "workout", "description": "I ran 5km", "exercise": "running", "distance_km": 5}, # Represent distance explicitly if possible
                {"type": "meal", "description": "3 hard boiled eggs", "calories": 200, "protein": 20, "carbs": 2, "fat": 14}
            ]},
            "metadata": {"category": "mixed"}
        },
        {
            "input": {"prompt": "During the morning I had a bacon-egg-and-cheese, in the afternoon I don't remember, and now I'm having a small dish of lasagna."},
            "expected_output": {"response": [
                {"type": "meal", "description": "bacon-egg-and-cheese", "calories": 1000, "protein": 100, "carbs": 100, "fat": 100},
                {"type": "meal", "description": "a small dish of lasagna", "calories": 1000, "protein": 100, "carbs": 100, "fat": 100}
            ]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "I had a salad for lunch"},
            "expected_output": {"response": [{"type": "meal", "description": "a salad", "calories": 100, "protein": 10, "carbs": 10, "fat": 10}]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "Hey, how are you doing?"},
            "expected_output": {"response": {"type": "error"}},
            "metadata": {"category": "unknown"}
        },
        {
            "input": {"prompt": "Started my day with overnight oats with berries, had a protein shake after my workout, and finished with grilled salmon and quinoa for dinner"},
            "expected_output": {"response": [
                {"type": "meal", "description": "overnight oats with berries", "calories": 350, "protein": 12, "carbs": 56, "fat": 8},
                {"type": "meal", "description": "protein shake", "calories": 160, "protein": 30, "carbs": 3, "fat": 2},
                {"type": "meal", "description": "grilled salmon and quinoa", "calories": 650, "protein": 45, "carbs": 45, "fat": 28}
            ]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "Had authentic pad thai from the street vendor and 2 mango sticky rice for dessert"},
            "expected_output": {"response": [
                {"type": "meal", "description": "pad thai", "calories": 600, "protein": 22, "carbs": 80, "fat": 25},
                {"type": "meal", "description": "2 mango sticky rice", "calories": 700, "protein": 8, "carbs": 140, "fat": 16}
            ]},
            "metadata": {"category": "nutrition"}
        },
        {
            "input": {"prompt": "45min HIIT session followed by 2 protein bars and a banana"},
            "expected_output": {"response": [
                {"type": "workout", "description": "45min HIIT session", "exercise": "HIIT", "duration_seconds": 2700},
                {"type": "meal", "description": "2 protein bars", "calories": 440, "protein": 40, "carbs": 44, "fat": 16},
                {"type": "meal", "description": "banana", "calories": 105, "protein": 1, "carbs": 27, "fat": 0}
            ]},
            "metadata": {"category": "mixed"}
        },
        {
            "input": {"prompt": "I think I might grab something later"},
            "expected_output": {"response": {"type": "error"}},
            "metadata": {"category": "unknown"}
        },
        {
            "input": {"prompt": "Morning routine: 5k run, then 4x12 squats at 185lbs, finished with 10 minutes of stretching"},
            "expected_output": {"response": [
                {"type": "workout", "description": "5k run", "exercise": "running", "distance_km": 5},
                {"type": "workout", "description": "4x12 squats at 185lbs", "exercise": "squats", "series": 4, "reps": 12, "weight_kg": 84}, # Corrected weight
                {"type": "workout", "description": "10 minutes of stretching", "exercise": "stretching", "duration_seconds": 600}
            ]},
            "metadata": {"category": "exercise"}
        }
    ]

@pytest.fixture(scope="module")
def meals_workouts_dataset(experiments_vcr, meals_workouts_data):
    """
    Provides a Dataset instance for 'test-meals-workouts'.
    Pulls from remote if it exists, otherwise creates and pushes it.
    This ensures the dataset is available for tests that need it.
    """
    dataset_name = "test-meals-workouts"
    description = "Dataset for testing meals and workouts parsing (created by tests)"

    with experiments_vcr.use_cassette("test_dataset_meals_workouts_setup.yaml"):
        try:
            print(f"\nAttempting to pull dataset '{dataset_name}'...")
            dataset = dne.Dataset.pull(name=dataset_name)
            print(f"Successfully pulled existing dataset '{dataset_name}' version {dataset._datadog_dataset_version}")
            # Optional: If you want to ensure the *content* matches the fixture data,
            # you could push with overwrite=True here, but usually pulling is enough.
            # dataset = dne.Dataset(name=dataset_name, data=meals_workouts_data, description=description)
            # dataset.push(overwrite=True)
            # print(f"Overwrote dataset '{dataset_name}' to ensure content matches tests.")

        except ValueError as e:
            if "not found" in str(e):
                print(f"Dataset '{dataset_name}' not found. Creating and pushing...")
                dataset = dne.Dataset(
                    name=dataset_name,
                    data=meals_workouts_data,
                    description=description
                )
                # Push to create it remotely. new_version=True ensures it creates if deleted/recreated.
                dataset.push(new_version=True)
                print(f"Successfully created and pushed dataset '{dataset_name}' version {dataset._datadog_dataset_version}")
            else:
                # Re-raise other ValueErrors (e.g., version not found if specified)
                raise e
    return dataset

# --- Test Classes ---

class TestDatasetInitialization:
    """Tests for Dataset.__init__ behavior."""

    def test_init_local_data_simple(self, local_dataset_simple, sample_data_simple):
        """Initialize with simple local data."""
        assert local_dataset_simple.name == "test-local-simple"
        assert local_dataset_simple.description == "Simple math/geo"
        assert local_dataset_simple._data == sample_data_simple # Check internal data directly here
        assert_dataset_local(local_dataset_simple, expected_len=len(sample_data_simple))

    def test_init_local_data_dict(self, local_dataset_dict, sample_data_dict):
        """Initialize with dictionary local data."""
        assert local_dataset_dict.name == "test-local-dict"
        assert local_dataset_dict._data == sample_data_dict
        assert_dataset_local(local_dataset_dict, expected_len=len(sample_data_dict))

    def test_init_local_data_mixed(self, local_dataset_mixed, sample_data_mixed):
        """Initialize with mixed local data and metadata."""
        assert local_dataset_mixed.name == "test-local-mixed"
        assert local_dataset_mixed._data == sample_data_mixed
        assert_dataset_local(local_dataset_mixed, expected_len=len(sample_data_mixed))

    def test_init_data_empty(self):
        """Initialize with empty data is allowed."""
        dataset = dne.Dataset(name="empty-data", data=[])
        assert dataset.name == "empty-data"
        assert dataset._data == []
        assert dataset._datadog_dataset_id is None
        assert dataset._datadog_dataset_version == 0

    def test_init_invalid_data_too_large(self):
        """Initialize with data exceeding MAX_DATASET_ROWS raises ValueError."""
        large_data = [{"input": f"q{i}", "expected_output": f"a{i}"} for i in range(MAX_DATASET_ROWS + 1)]
        with pytest.raises(ValueError, match=f"Dataset cannot exceed {MAX_DATASET_ROWS} rows"):
            dne.Dataset(name="large-data", data=large_data)

    def test_init_invalid_data_inconsistent_keys(self):
        """Initialize with inconsistent keys raises ValueError."""
        inconsistent_data = [
            {"input": "q1", "expected_output": "a1"},
            {"input": "q2", "different_key": "a2"},
        ]
        # Update the expected error message to be more specific and match the actual output.
        # Sorting ensures the key order in the message is predictable.
        expected_keys_sorted = sorted(['input', 'expected_output'])
        got_keys_sorted = sorted(['input', 'different_key'])
        # Escape the string representations of the lists for the regex pattern
        expected_keys_str_escaped = re.escape(str(expected_keys_sorted))
        got_keys_str_escaped = re.escape(str(got_keys_sorted))
        expected_message_regex = (
            rf"Inconsistent keys in data. Expected {expected_keys_str_escaped}, "
            rf"got {got_keys_str_escaped}"
        )
        with pytest.raises(ValueError, match=expected_message_regex):
            dne.Dataset(name="inconsistent-keys", data=inconsistent_data)

    def test_init_invalid_data_not_dicts(self):
        """Initialize with list containing non-dicts raises ValueError."""
        invalid_data = [{"input": "q1", "expected_output": "a1"}, "not a dict"]
        with pytest.raises(ValueError, match="All rows must be dictionaries"):
            dne.Dataset(name="not-dicts", data=invalid_data)

    def test_init_local_data_diverse(self, local_dataset_diverse, sample_data_diverse):
        """Initialize with diverse local data types."""
        assert local_dataset_diverse.name == "test-local-diverse"
        assert local_dataset_diverse.description == "Diverse types"
        assert local_dataset_diverse._data == sample_data_diverse
        assert_dataset_local(local_dataset_diverse, expected_len=len(sample_data_diverse))

    def test_init_implicit_pull_existing(self, experiments_vcr, meals_workouts_dataset):
        """Initialize with name only implicitly pulls existing dataset."""
        dataset_name = meals_workouts_dataset.name # Get name from fixture

        # Use a cassette specific to *this test's* operation (implicit pull)
        with experiments_vcr.use_cassette("test_dataset_init_implicit_pull_existing.yaml"):
            # This initialization should now succeed because the fixture ensured the dataset exists
            dataset = dne.Dataset(name=dataset_name)

        assert dataset.name == dataset_name
        # Assert it's synced (pulled state)
        assert_dataset_synced(dataset, expected_len=len(meals_workouts_dataset), expected_version=dataset._datadog_dataset_version)
        # Check specific content/structure from the first record pulled
        # Verify the core keys exist based on the actual cassette data
        assert "input" in dataset[0]
        assert "expected_output" in dataset[0]

    def test_init_implicit_pull_nonexistent(self, experiments_vcr):
        """Initialize with name only raises ValueError if dataset doesn't exist."""
        # This test remains valid, testing the error case for a name guaranteed not to exist
        dataset_name = "non-existent-dataset-for-init-test"
        with experiments_vcr.use_cassette("test_dataset_init_implicit_pull_nonexistent.yaml"):
            with pytest.raises(ValueError, match=f"Dataset '{dataset_name}' not found"):
                dne.Dataset(name=dataset_name)


class TestDatasetContainerOps:
    """Tests for container-like operations (__len__, __getitem__, __iter__)."""

    def test_len(self, local_dataset_simple, sample_data_simple):
        """Test len() returns correct number of records."""
        assert len(local_dataset_simple) == len(sample_data_simple)

    def test_getitem_index(self, local_dataset_mixed, sample_data_mixed):
        """Test getting item by index returns correct record (copy without record_id)."""
        record0 = local_dataset_mixed[0]
        assert record0 == sample_data_mixed[0]
        assert "record_id" not in record0

        record1 = local_dataset_mixed[1]
        assert record1 == sample_data_mixed[1]
        assert "record_id" not in record1

    def test_getitem_slice(self, local_dataset_mixed, sample_data_mixed):
        """Test getting item by slice returns correct records (copies without record_id)."""
        records = local_dataset_mixed[0:2]
        assert isinstance(records, list)
        assert len(records) == 2
        assert records[0] == sample_data_mixed[0]
        assert "record_id" not in records[0]
        assert records[1] == sample_data_mixed[1]
        assert "record_id" not in records[1]

    def test_getitem_index_out_of_bounds(self, local_dataset_simple):
        """Test getting index out of bounds raises IndexError."""
        with pytest.raises(IndexError):
            _ = local_dataset_simple[len(local_dataset_simple)]

    def test_iter(self, local_dataset_simple, sample_data_simple):
        """Test iterating through the dataset yields correct records."""
        iterations = 0
        for i, record in enumerate(local_dataset_simple):
             # Iteration yields internal dicts, which might have record_id later.
             # Compare by creating a comparable dict excluding potential record_id.
            record_copy = {k: v for k, v in record.items() if k != "record_id"}
            assert record_copy == sample_data_simple[i]
            iterations += 1
        assert iterations == len(sample_data_simple)


class TestDatasetModification:
    """Tests for local modification methods (add, update, remove, etc.) and change tracking."""

    def test_add_record(self, local_dataset_simple):
        """Test adding a valid record."""
        initial_len = len(local_dataset_simple)
        new_record = {"input": "New Q", "expected_output": "New A"}
        local_dataset_simple.add(new_record)

        assert local_dataset_simple[initial_len] == new_record # Check content via __getitem__
        assert local_dataset_simple._data[-1] == new_record    # Check internal state
        assert_dataset_unsynced(local_dataset_simple, expected_len=initial_len + 1, expected_version=0, added=1)

    def test_iadd_record(self, local_dataset_simple):
        """Test adding a valid record using +=."""
        initial_len = len(local_dataset_simple)
        new_record = {"input": "Another Q", "expected_output": "Another A"}
        local_dataset_simple += new_record

        assert local_dataset_simple[initial_len] == new_record
        assert_dataset_unsynced(local_dataset_simple, expected_len=initial_len + 1, expected_version=0, added=1)

    def test_add_invalid_record_structure(self, local_dataset_simple):
        """Test adding a record with invalid structure raises ValueError."""
        # Get the expected keys from the fixture dataset
        expected_keys_sorted = sorted(local_dataset_simple._data[0].keys())
        got_keys_sorted = sorted(["input", "wrong_key"])
        # Escape for regex
        expected_keys_str_escaped = re.escape(str(expected_keys_sorted))
        got_keys_str_escaped = re.escape(str(got_keys_sorted))
        expected_message_regex = (
            rf"Record structure doesn't match dataset\. Expected keys {expected_keys_str_escaped}, "
            rf"got {got_keys_str_escaped}"
        )
        with pytest.raises(ValueError, match=expected_message_regex): # Updated expected message
            local_dataset_simple.add({"input": "Bad", "wrong_key": "Data"})

    def test_setitem_update(self, local_dataset_dict):
        """Test updating a record using __setitem__."""
        index_to_update = 0
        original_record = local_dataset_dict._data[index_to_update].copy() # Keep original internal state for tracking
        new_record_data = {"input": {"prompt": "New prompt"}, "expected_output": {"response": "New response"}}
        local_dataset_dict[index_to_update] = new_record_data

        assert len(local_dataset_dict) == 2
        assert local_dataset_dict[index_to_update] == new_record_data
        assert local_dataset_dict._data[index_to_update] == new_record_data
        assert_dataset_unsynced(local_dataset_dict, expected_len=2, expected_version=0, updated=1)
        # Check exact change tracked if needed
        assert local_dataset_dict._changes['updated'] == [(index_to_update, original_record, new_record_data)]

    def test_update_method(self, local_dataset_dict):
        """Test updating a record using the update() method."""
        index_to_update = 1
        original_record = local_dataset_dict._data[index_to_update].copy()
        new_record_data = {"input": {"prompt": "Updated prompt 2"}, "expected_output": {"response": "Updated response 2"}}
        local_dataset_dict.update(index_to_update, new_record_data)

        assert local_dataset_dict[index_to_update] == new_record_data
        assert_dataset_unsynced(local_dataset_dict, expected_len=2, expected_version=0, updated=1)
        # Check exact change tracked if needed
        assert local_dataset_dict._changes['updated'] == [(index_to_update, original_record, new_record_data)]

    def test_setitem_invalid_structure(self, local_dataset_simple):
        """Test updating with invalid structure raises ValueError."""
        # Get the expected keys from the fixture dataset, excluding potential record_id
        expected_keys_sorted = sorted([k for k in local_dataset_simple._data[0].keys() if k != 'record_id'])
        got_keys_sorted = sorted(["input", "wrong_key"])
        # Escape for regex
        expected_keys_str_escaped = re.escape(str(expected_keys_sorted))
        got_keys_str_escaped = re.escape(str(got_keys_sorted))
        expected_message_regex = (
            rf"Record structure doesn't match dataset\. Expected keys {expected_keys_str_escaped}, "
            rf"got {got_keys_str_escaped}"
        )
        with pytest.raises(ValueError, match=expected_message_regex): # Updated expected message
            local_dataset_simple[0] = {"input": "Bad", "wrong_key": "Data"}

    def test_delitem_remove(self, local_dataset_mixed):
        """Test removing a record using __delitem__."""
        index_to_delete = 0
        initial_len = len(local_dataset_mixed)
        original_record = local_dataset_mixed._data[index_to_delete].copy() # Keep original internal state for tracking
        expected_remaining_record = local_dataset_mixed[1] # Record that will shift to index 0 after deletion

        del local_dataset_mixed[index_to_delete]

        assert len(local_dataset_mixed) == initial_len - 1
        assert local_dataset_mixed[0] == expected_remaining_record
        assert_dataset_unsynced(local_dataset_mixed, expected_len=initial_len - 1, expected_version=0, deleted=1)
        # Check exact change tracked if needed
        assert local_dataset_mixed._changes['deleted'] == [(index_to_delete, original_record)]

    def test_remove_method(self, local_dataset_mixed):
        """Test removing a record using the remove() method."""
        index_to_delete = 1
        initial_len = len(local_dataset_mixed)
        original_record = local_dataset_mixed._data[index_to_delete].copy()
        expected_remaining_record = local_dataset_mixed[0] # Record that will remain at index 0

        local_dataset_mixed.remove(index_to_delete)

        assert len(local_dataset_mixed) == initial_len - 1
        assert local_dataset_mixed[0] == expected_remaining_record
        assert_dataset_unsynced(local_dataset_mixed, expected_len=initial_len - 1, expected_version=0, deleted=1)
        # Check exact change tracked if needed
        assert local_dataset_mixed._changes['deleted'] == [(index_to_delete, original_record)]

    def test_multiple_operations_tracking(self, local_dataset_simple):
        """Test change tracking after multiple add, update, delete operations."""
        initial_len = len(local_dataset_simple)
        original_rec0 = local_dataset_simple._data[0].copy()
        original_rec1 = local_dataset_simple._data[1].copy()

        # 1. Add a record
        new_record1 = {"input": "Q3", "expected_output": "A3"}
        local_dataset_simple.add(new_record1) # State: [rec0, rec1, new1], len=3, added=1

        # 2. Update the first record
        updated_rec0_data = {"input": "Q1 Updated", "expected_output": "A1 Updated"}
        local_dataset_simple[0] = updated_rec0_data # State: [upd0, rec1, new1], len=3, added=1, updated=1

        # 3. Delete the second original record (now at index 1)
        deleted_rec1_original_index = 1
        del local_dataset_simple[1] # State: [upd0, new1], len=2, added=1, updated=1, deleted=1

        # 4. Add another record
        new_record2 = {"input": "Q4", "expected_output": "A4"}
        local_dataset_simple.add(new_record2) # State: [upd0, new1, new2], len=3, added=2, updated=1, deleted=1

        # Assert final content
        assert local_dataset_simple[0] == updated_rec0_data
        assert local_dataset_simple[1] == new_record1
        assert local_dataset_simple[2] == new_record2

        # Assert final sync state and tracked changes using helper
        assert_dataset_unsynced(local_dataset_simple, expected_len=3, expected_version=0, added=2, updated=1, deleted=1)

        # Optionally verify exact changes if needed (helper doesn't check content)
        assert local_dataset_simple._changes['added'] == [new_record1, new_record2]
        assert local_dataset_simple._changes['updated'] == [(0, original_rec0, updated_rec0_data)]
        assert local_dataset_simple._changes['deleted'] == [(deleted_rec1_original_index, original_rec1)]



class TestDatasetPull:
    """Tests for Dataset.pull (explicitly pulling from Datadog)."""

    def test_pull_latest_version(self, experiments_vcr, meals_workouts_dataset):
        """Test pulling the latest version of an existing dataset."""
        dataset_name = meals_workouts_dataset.name # Get name from fixture

        with experiments_vcr.use_cassette("test_dataset_pull_latest_meals_workouts.yaml"): # Updated cassette name
            dataset = dne.Dataset.pull(dataset_name)

        assert dataset.name == dataset_name
        # Version check done by helper
        assert_dataset_synced(dataset, expected_len=len(meals_workouts_dataset), expected_version=dataset._datadog_dataset_version)
        # Check structure/content sample
        assert "input" in dataset[0]
        assert "expected_output" in dataset[0]
        assert "metadata" in dataset[0]
        assert "record_id" in dataset._data[0]
        assert isinstance(dataset._data[0]["record_id"], str)

    def test_pull_specific_version(self, experiments_vcr, meals_workouts_dataset):
        """Test pulling a specific, existing version of a dataset."""
        dataset_name = meals_workouts_dataset.name
        # We know the fixture creates/pulls at least version 1
        version_to_pull = 1
        # Ensure the setup cassette ran and pushed/pulled version 1
        assert meals_workouts_dataset._datadog_dataset_version >= version_to_pull

        with experiments_vcr.use_cassette("test_dataset_pull_specific_version_meals_workouts.yaml"): # Updated cassette name
            dataset = dne.Dataset.pull(dataset_name, version=version_to_pull)

        assert dataset.name == dataset_name
        # Explicit version check is core to this test, helper confirms sync state
        assert_dataset_synced(dataset, expected_len=len(meals_workouts_dataset), expected_version=version_to_pull)
        assert "record_id" in dataset._data[0]

    def test_pull_nonexistent_dataset(self, experiments_vcr):
        """Test pulling a non-existent dataset raises ValueError."""
        dataset_name = "this-dataset-definitely-should-not-exist"
        with experiments_vcr.use_cassette("test_dataset_pull_nonexistent.yaml"):
            with pytest.raises(ValueError, match=f"Dataset '{dataset_name}' not found"):
                dne.Dataset.pull(dataset_name)

    def test_pull_nonexistent_version(self, experiments_vcr, meals_workouts_dataset):
        """Test pulling a non-existent version raises ValueError."""
        dataset_name = meals_workouts_dataset.name
        non_existent_version = 9999
        with experiments_vcr.use_cassette("test_dataset_pull_nonexistent_version_meals_workouts.yaml"): # Updated cassette name
            # Match needs to check for the specific version not found message
            with pytest.raises(ValueError, match=f"Version {non_existent_version} not found for dataset '{dataset_name}'"):
                dne.Dataset.pull(dataset_name, version=non_existent_version)

    def test_pull_empty_dataset(self, experiments_vcr):
        """Test pulling a dataset that exists with no records works correctly."""
        # This dataset exists but has no records
        dataset_name = "existing-but-empty"
        with experiments_vcr.use_cassette("test_dataset_pull_empty.yaml"):
            dataset = dne.Dataset.pull(dataset_name)
            assert isinstance(dataset, dne.Dataset)
            assert dataset.name == dataset_name
            assert len(dataset) == 0  # Verify it has zero records


class TestDatasetPush:
    """Tests for dataset.push() interactions with Datadog."""

    # Helper to generate unique names for recording new datasets
    def _unique_name(self, prefix="test-push"):
        return f"{prefix}-{uuid.uuid4().hex[:8]}"

    # --- Scenario: New Local Dataset ---
    def test_push_new_local_dataset(self, experiments_vcr, local_dataset_simple):
        """Test pushing a completely new local dataset."""
        # Use a unique name to ensure it's new during recording/playback
        unique_name = self._unique_name("test-push-new")
        local_dataset_simple.name = unique_name # Rename for push

        with experiments_vcr.use_cassette("test_dataset_push_new.yaml"):
            local_dataset_simple.push()

        assert local_dataset_simple.name == unique_name
        # Check sync status, len, version, and record_id presence using helper
        assert_dataset_synced(local_dataset_simple, expected_len=2, expected_version=local_dataset_simple._datadog_dataset_version)
        # Version should be > 0 after push, exact value checked by helper
        assert local_dataset_simple._datadog_dataset_version is not None
        # Verify internal data now has record_ids after the implicit refresh post-push
        assert len(local_dataset_simple._data) == 2
        assert "record_id" in local_dataset_simple._data[0]
        assert isinstance(local_dataset_simple._data[0]["record_id"], str)
        assert "record_id" in local_dataset_simple._data[1]

    # --- Scenario: Synced Dataset ---
    @pytest.fixture
    def synced_dataset(self, experiments_vcr, meals_workouts_dataset):
        """Fixture to provide a dataset pulled from remote, ready for modifications."""
        # The meals_workouts_dataset fixture already ensures the dataset exists.
        # We just need to pull it *again* within this test's context/cassette
        # to get a fresh, independent instance for modification tests.
        dataset_name = meals_workouts_dataset.name
        with experiments_vcr.use_cassette("test_dataset_pull_for_sync_tests.yaml"): # Cassette for pulling within sync tests
             dataset = dne.Dataset.pull(dataset_name)
        assert dataset._synced is True
        assert dataset._datadog_dataset_id is not None
        return dataset

    def test_push_synced_no_changes(self, experiments_vcr, synced_dataset, capsys):
        """Test pushing a synced dataset with no local changes."""
        initial_len = len(synced_dataset)
        initial_version = synced_dataset._datadog_dataset_version

        # This cassette should ideally show no POST requests or minimal GETs
        with experiments_vcr.use_cassette("test_dataset_push_synced_no_change.yaml"):
            synced_dataset.push()

        captured = capsys.readouterr()
        assert f"Dataset '{synced_dataset.name}' (v{initial_version}) is already synced and has no pending changes" in captured.out

    def test_push_synced_with_adds(self, experiments_vcr, synced_dataset):
        """Test push after adding records (default: creates new version via batch update)."""
        initial_version = synced_dataset._datadog_dataset_version
        initial_len = len(synced_dataset)
        # Use structure consistent with the pulled 'meals-and-workouts-1.3' dataset
        new_record = {"input": {"prompt": "new workout?"}, "expected_output": {"response": "pushups"}}

        # Add record and verify unsynced state
        synced_dataset.add(new_record)
        assert_dataset_unsynced(synced_dataset, expected_len=initial_len + 1, expected_version=initial_version, added=1)

        with experiments_vcr.use_cassette("test_dataset_push_synced_adds.yaml"):
            # Should trigger _batch_update internally
            synced_dataset.push()

        # Verify synced state after push (new version)
        assert_dataset_synced(synced_dataset, expected_len=initial_len + 1, expected_version=initial_version + 1)
        # Check content of added record (now has record_id)
        assert synced_dataset[-1]["input"] == new_record["input"]

    def test_push_synced_with_deletes(self, experiments_vcr, synced_dataset):
        """Test push after deleting records (default: creates new version via batch update)."""
        initial_version = synced_dataset._datadog_dataset_version
        initial_len = len(synced_dataset)
        assert initial_len > 0
        # Record the ID before deleting, needed for batch update payload matching in VCR
        deleted_record_id = synced_dataset._data[0]["record_id"]

        # Delete and verify unsynced state
        del synced_dataset[0]
        assert_dataset_unsynced(synced_dataset, expected_len=initial_len - 1, expected_version=initial_version, deleted=1)
        # Ensure the correct ID is captured for cassette matching.
        assert synced_dataset._changes['deleted'][0][1]['record_id'] == deleted_record_id

        with experiments_vcr.use_cassette("test_dataset_push_synced_deletes.yaml"):
            # Should trigger _batch_update internally
            synced_dataset.push()

        # Verify synced state after push (new version)
        assert_dataset_synced(synced_dataset, expected_len=initial_len - 1, expected_version=initial_version + 1)

    def test_push_synced_with_updates(self, experiments_vcr, synced_dataset):
        """Test push after updating records (default: creates new version via batch update)."""
        initial_version = synced_dataset._datadog_dataset_version
        initial_len = len(synced_dataset)
        assert initial_len > 0
        # Record the ID before updating for VCR matching
        original_record = synced_dataset._data[0].copy()
        updated_record_id = original_record["record_id"]
        updated_record_data = {"input": {"prompt": "updated prompt"}, "expected_output": {"response": "updated response"}}

        # Update and verify unsynced state
        synced_dataset[0] = updated_record_data
        assert_dataset_unsynced(synced_dataset, expected_len=initial_len, expected_version=initial_version, updated=1)
        # Ensure the correct ID is captured for VCR cassette body matching
        assert synced_dataset._changes['updated'][0][1]['record_id'] == updated_record_id # old_record has ID
        assert "record_id" not in synced_dataset._changes['updated'][0][2] # new_record doesn't (API adds it)

        with experiments_vcr.use_cassette("test_dataset_push_synced_updates.yaml"):
            # Should trigger _batch_update internally
            synced_dataset.push()

        # Verify synced state after push (new version)
        assert_dataset_synced(synced_dataset, expected_len=initial_len, expected_version=initial_version + 1)
        # Check if the updated record still has its ID internally after refresh
        assert synced_dataset[0] == updated_record_data

    def test_push_synced_mixed_changes(self, experiments_vcr, synced_dataset):
        """Test push after mixed add/update/delete (default: new version via batch update)."""
        initial_version = synced_dataset._datadog_dataset_version
        initial_len = len(synced_dataset)
        assert initial_len >= 2 # Need >= 2 records for this mixed test

        # 1. Update record 0
        updated_record_id = synced_dataset._data[0]["record_id"]
        updated_record_data = {"input": {"prompt": "mixed update"}, "expected_output": {"response": "mixed update resp"}}
        synced_dataset[0] = updated_record_data

        # 2. Delete record 1
        deleted_record_id = synced_dataset._data[1]["record_id"]
        del synced_dataset[1]

        # 3. Add a new record
        new_record = {"input": {"prompt": "mixed add"}, "expected_output": {"response": "mixed add resp"}}
        synced_dataset.add(new_record)

        # Verify intermediate unsynced state
        assert_dataset_unsynced(synced_dataset, expected_len=initial_len, expected_version=initial_version, added=1, deleted=1, updated=1)
        # Prepare VCR match data (relies on internal _changes)
        assert synced_dataset._changes['updated'][0][1]['record_id'] == updated_record_id
        assert synced_dataset._changes['deleted'][0][1]['record_id'] == deleted_record_id
        assert synced_dataset._changes['added'][0] == new_record

        with experiments_vcr.use_cassette("test_dataset_push_synced_mixed.yaml"):
            # Should trigger _batch_update internally
            synced_dataset.push()

        # Verify final synced state (new version)
        assert_dataset_synced(synced_dataset, expected_len=initial_len, expected_version=initial_version + 1)
        # Verify updates/adds persisted and have IDs after refresh
        assert synced_dataset[0] == updated_record_data
        assert synced_dataset[-1]["input"] == new_record["input"]

    def test_push_synced_overwrite(self, experiments_vcr, synced_dataset):
        """Test push with overwrite=True after modifications (uses /push endpoint)."""
        initial_id = synced_dataset._datadog_dataset_id
        initial_version = synced_dataset._datadog_dataset_version
        initial_len = len(synced_dataset)

        deleted_record_id = synced_dataset._data[0]["record_id"]
        del synced_dataset[0]
        assert_dataset_unsynced(synced_dataset, expected_len=initial_len - 1, expected_version=initial_version, deleted=1)

        with experiments_vcr.use_cassette("test_dataset_push_synced_overwrite.yaml"):
            # Should trigger _push_entire_dataset(overwrite=True) internally
            synced_dataset.push(overwrite=True)

        # Verify synced state - ID should be the same, version might change or stay same
        # We capture the version *after* the push for the helper check
        final_version = synced_dataset._datadog_dataset_version
        assert synced_dataset._datadog_dataset_id == initial_id # ID must remain the same
        assert final_version >= initial_version # Version should be >= initial
        assert_dataset_synced(synced_dataset, expected_len=initial_len - 1, expected_version=final_version)
        assert not any(r['record_id'] == deleted_record_id for r in synced_dataset._data)

    def test_push_synced_new_version(self, experiments_vcr, synced_dataset):
        """Test push with new_version=True after modifications (uses /push endpoint)."""
        initial_id = synced_dataset._datadog_dataset_id
        initial_version = synced_dataset._datadog_dataset_version
        initial_len = len(synced_dataset)

        new_record = {"input": {"prompt": "new version add"}, "expected_output": {"response": "nv add resp"}}
        synced_dataset.add(new_record)
        assert_dataset_unsynced(synced_dataset, expected_len=initial_len + 1, expected_version=initial_version, added=1)

        with experiments_vcr.use_cassette("test_dataset_push_synced_new_version.yaml"):
            # Should trigger _push_entire_dataset(overwrite=False) internally
            synced_dataset.push(new_version=True)

        # Verify synced state - ID stays same, version must increment
        assert synced_dataset._datadog_dataset_id == initial_id
        assert_dataset_synced(synced_dataset, expected_len=initial_len + 1, expected_version=initial_version + 1)
        assert synced_dataset[-1]["input"] == new_record["input"]

    # --- Scenario: Local Dataset with Name Collision ---
    @pytest.fixture
    def local_colliding_dataset(self, sample_data_simple, experiments_vcr, meals_workouts_dataset):
        """ Local dataset whose name matches an existing one ('test-meals-workouts')."""
        # meals_workouts_dataset fixture ensures the remote one exists.
        dataset_name = meals_workouts_dataset.name # Use the correct name
        # Create local dataset with the *same name* but different data
        return dne.Dataset(name=dataset_name, data=sample_data_simple)

    def test_push_local_collision_no_flags(self, experiments_vcr, local_colliding_dataset, capsys):
        """Test push() on local dataset with name collision warns and does nothing."""
        initial_data = local_colliding_dataset._data[:] # Copy data
        with experiments_vcr.use_cassette("test_dataset_push_collision_no_flags.yaml"):
            # Should only do a GET to check existence
            local_colliding_dataset.push()

        captured = capsys.readouterr()
        assert f"Dataset '{local_colliding_dataset.name}' already exists" in captured.out
        assert "Use push(overwrite=True)" in captured.out
        assert "push(new_version=True)" in captured.out
        # Verify state remains local and unchanged using helper
        assert_dataset_local(local_colliding_dataset, expected_len=len(initial_data))
        assert local_colliding_dataset._data == initial_data


    def test_push_local_collision_overwrite(self, experiments_vcr, local_colliding_dataset):
        """Test push(overwrite=True) on local dataset with name collision."""
        dataset_name = local_colliding_dataset.name
        original_local_data_count = len(local_colliding_dataset)
        original_local_first_record_content = local_colliding_dataset[0]

        with experiments_vcr.use_cassette("test_dataset_push_collision_overwrite.yaml"):
            # Should trigger _push_entire_dataset(overwrite=True) after finding existing ID via GET
            local_colliding_dataset.push(overwrite=True)

        # Verify it's now synced, length is same, version is whatever the backend returned
        final_version = local_colliding_dataset._datadog_dataset_version
        assert local_colliding_dataset.name == dataset_name
        assert_dataset_synced(local_colliding_dataset, expected_len=original_local_data_count, expected_version=final_version)
        assert local_colliding_dataset[0] == original_local_first_record_content

    def test_push_local_collision_new_version(self, experiments_vcr, local_colliding_dataset):
        """Test push(new_version=True) on local dataset with name collision."""
        dataset_name = local_colliding_dataset.name
        original_local_data_count = len(local_colliding_dataset)
        original_local_first_record_content = local_colliding_dataset[0]

        # We need the original remote version number for comparison
        remote_version = 0
        with experiments_vcr.use_cassette("test_dataset_push_collision_new_version_check.yaml"):
             remote_id = local_colliding_dataset._get_remote_dataset_id_and_version()[1] # Get version
             # If pull works, we get the version. If not, assume it's 0 or handle error.
             # This is a bit fragile, better to fetch explicitly if needed.
             # Let's assume the cassette correctly captures the GET /datasets?filter[name]=...
             # and we extract the version from there. (Requires VCR logic)
             # For simplicity here, let's assume the pre-existing version is captured in the cassette
             # and the _push_entire_dataset logic correctly increments it.
             # The test below relies on the push() call doing the right thing.

        with experiments_vcr.use_cassette("test_dataset_push_collision_new_version.yaml"):
            # Should trigger _push_entire_dataset(overwrite=False) after finding existing ID via GET
            local_colliding_dataset.push(new_version=True)

        # Verify it's synced, length same, version should be incremented from remote
        final_version = local_colliding_dataset._datadog_dataset_version
        assert local_colliding_dataset.name == dataset_name
        # We expect the version to be incremented. Without knowing the *previous* version reliably,
        # we can assert it's > 0 if the original existed.
        # The helper asserts sync status.
        assert_dataset_synced(local_colliding_dataset, expected_len=original_local_data_count, expected_version=final_version)
        assert final_version > 0 # Assuming remote existed with some version >= 0
        assert local_colliding_dataset[0] == original_local_first_record_content

    # --- Error/Edge Cases ---
    def test_push_overwrite_and_new_version_flags(self, local_dataset_simple):
        """Test push() with both overwrite and new_version flags raises ValueError."""
        with pytest.raises(ValueError, match="Cannot specify both overwrite=True and new_version=True"):
            local_dataset_simple.push(overwrite=True, new_version=True)

    def test_push_large_dataset_chunking(self, experiments_vcr):
        """Test pushing a dataset large enough to trigger chunking."""
        # Create data slightly larger than one chunk to ensure > 1 push request
        num_records = DEFAULT_CHUNK_SIZE + 5
        large_data = [{"input": f"q{i}", "expected_output": f"a{i}"} for i in range(num_records)]
        dataset = dne.Dataset(name=self._unique_name("test-push-large"), data=large_data)

        # Cassette should show multiple POST requests to the /push endpoint due to chunking
        with experiments_vcr.use_cassette("test_dataset_push_large_chunking.yaml"):
            dataset.push()

        # Verify synced state after chunked push
        assert_dataset_synced(dataset, expected_len=num_records, expected_version=dataset._datadog_dataset_version)

    def test_push_update_delete_missing_record_id(self, synced_dataset):
        """Test internal logic guards against updates/deletes without record_id (difficult to trigger externally)."""
        # This tests the safeguard within _prepare_batch_payload.

        # Simulate a scenario where a record intended for update/delete lacks a record_id internally
        # (This shouldn't happen with normal usage, but tests the internal check)

        # 1. Simulate an update where old_record is missing 'record_id'
        synced_dataset._changes['updated'].append((0, {"input": "no id"}, {"input": "new"}))
        with pytest.raises(ValueError, match="Cannot update record: missing record_id"):
            synced_dataset._prepare_batch_payload(overwrite=False)
        synced_dataset._changes['updated'] = []

        # 2. Simulate a delete where the record is missing 'record_id'
        synced_dataset._changes['deleted'].append((0, {"input": "no id"}))
        with pytest.raises(ValueError, match="Cannot delete record: missing record_id"):
            synced_dataset._prepare_batch_payload(overwrite=False)
        synced_dataset._changes['deleted'] = []


class TestDatasetFromCSV:
    """Tests for Dataset.from_csv functionality."""

    @pytest.fixture
    def csv_file_simple(self):
        """Path to a simple CSV file."""
        return "tests/llmobs/experiments_files/simple.csv"

    @pytest.fixture
    def csv_file_multi_col(self):
        """Path to a CSV with multiple input/output columns and metadata."""
        return "tests/llmobs/experiments_files/multi.csv"

    @pytest.fixture
    def csv_file_delimiter(self):
        """Path to a CSV with a semicolon delimiter."""
        return "tests/llmobs/experiments_files/delimiter.tsv"

    @pytest.fixture
    def csv_file_empty(self):
        """Path to an empty CSV file."""
        return "tests/llmobs/experiments_files/empty.csv"

    @pytest.fixture
    def csv_file_header_only(self):
        """Path to a CSV file with only a header."""
        return "tests/llmobs/experiments_files/header_only.csv"

    @pytest.fixture
    def csv_file_malformed(self):
        """Path to a malformed CSV file."""
        return "tests/llmobs/experiments_files/malformed.csv"

    def test_from_csv_simple(self, csv_file_simple):
        """Test loading simple CSV with single input/output columns."""
        dataset = dne.Dataset.from_csv(
            csv_file_simple,
            name="csv-simple",
            description="From simple CSV",
            input_columns=["question"],
            expected_output_columns=["answer"]
        )
        assert dataset.name == "csv-simple"
        assert dataset.description == "From simple CSV"
        assert len(dataset) == 4
        assert dataset[0] == {"input": "What is 1+1?", "expected_output": "2"}
        assert dataset[1] == {"input": "Capital of UK?", "expected_output": "London"}
        assert dataset[3] == {"input": "How many continents?", "expected_output": "7"}
        assert dataset._synced is True # Local dataset is considered synced with its initial state

    def test_from_csv_multi_column_and_metadata(self, csv_file_multi_col):
        """Test loading CSV with multiple input/output columns and metadata."""
        dataset = dne.Dataset.from_csv(
            csv_file_multi_col,
            name="csv-multi",
            input_columns=["prompt", "context"],
            expected_output_columns=["expected_response", "expected_certainty"]
        )
        assert dataset.name == "csv-multi"
        assert len(dataset) == 4
        assert dataset[0] == {
            "input": {"prompt": "France capital?", "context": ""},
            "expected_output": {"expected_response": "Paris", "expected_certainty": "0.9"},
            "category": "geography", # Metadata automatically included
            "difficulty": "easy"      # Metadata automatically included
        }
        assert dataset[1] == {
            "input": {"prompt": "Largest planet?", "context": "Solar System"},
            "expected_output": {"expected_response": "Jupiter", "expected_certainty": "1.0"},
            "category": "astronomy",
            "difficulty": "medium"
        }
        assert dataset[3] == {
            "input": {"prompt": "Calculate 2+3", "context": "Math basics"},
            "expected_output": {"expected_response": "5", "expected_certainty": "1.0"},
            "category": "mathematics",
            "difficulty": "easy"
        }


    def test_from_csv_different_delimiter(self, csv_file_delimiter):
        """Test loading CSV with a non-comma delimiter."""
        dataset = dne.Dataset.from_csv(
            csv_file_delimiter,
            name="csv-delimiter",
            delimiter=";",
            input_columns=["input"],
            expected_output_columns=["output"]
        )
        assert len(dataset) == 4
        assert dataset[0] == {"input": "Hello", "expected_output": "World", "metadata": "greeting"}
        assert dataset[1] == {"input": "Test", "expected_output": "Data", "metadata": "sample"}
        assert dataset[3] == {"input": "How are you?", "expected_output": "Fine, thanks", "metadata": "conversation"}


    def test_from_csv_empty_file(self, csv_file_empty):
        """Test loading from an empty CSV file raises ValueError."""
        # This check happens *after* opening the file successfully but before reading content
        with pytest.raises(ValueError, match="CSV file appears to be empty or header is missing."):
            dne.Dataset.from_csv(csv_file_empty, name="bad", input_columns=["a"], expected_output_columns=["b"])

    def test_from_csv_header_only_file(self, csv_file_header_only):
        """Test loading from a CSV file with only a header raises ValueError."""
        with pytest.raises(ValueError, match="CSV file is empty"):
            dne.Dataset.from_csv(csv_file_header_only, name="bad", input_columns=["col1"], expected_output_columns=["col2"])

    def test_from_csv_missing_input_column(self, csv_file_simple):
        """Test loading when specified input column is missing raises ValueError."""
        with pytest.raises(ValueError, match="Input columns not found in CSV header: \\['missing_input'\\]"):
            dne.Dataset.from_csv(csv_file_simple, name="bad", input_columns=["missing_input"], expected_output_columns=["answer"])

    def test_from_csv_missing_output_column(self, csv_file_simple):
        """Test loading when specified output column is missing raises ValueError."""
        with pytest.raises(ValueError, match="Expected output columns not found in CSV header: \\['missing_output'\\]"):
            dne.Dataset.from_csv(csv_file_simple, name="bad", input_columns=["question"], expected_output_columns=["missing_output"])

    def test_from_csv_missing_column_specifications(self, csv_file_simple):
        """Test calling from_csv without input/output columns raises ValueError."""
        with pytest.raises(ValueError, match="`input_columns` and `expected_output_columns` must be provided"):
            dne.Dataset.from_csv(csv_file_simple, name="bad")
        with pytest.raises(ValueError, match="`input_columns` and `expected_output_columns` must be provided"):
            dne.Dataset.from_csv(csv_file_simple, name="bad", input_columns=["question"])
        with pytest.raises(ValueError, match="`input_columns` and `expected_output_columns` must be provided"):
            dne.Dataset.from_csv(csv_file_simple, name="bad", expected_output_columns=["answer"])

    def test_from_csv_malformed_file(self, csv_file_malformed):
        """Test loading a malformed CSV raises DatasetFileError."""
        with pytest.raises(DatasetFileError, match="Error parsing CSV file"):
            dne.Dataset.from_csv(csv_file_malformed, name="bad", input_columns=["head1"], expected_output_columns=["head2"])

    # Test for permission error is hard to reliably simulate across platforms and CI


class TestDatasetRepr:
    """Tests for the __repr__ output of the Dataset."""

    # Helper to strip ANSI color codes for easier comparison
    def _strip_ansi(self, text):
        import re
        ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
        return ansi_escape.sub('', text)

    def test_repr_local_only(self, local_dataset_simple):
        """Test repr for a new, local-only dataset."""
        rep = repr(local_dataset_simple)
        rep_clean = self._strip_ansi(rep)

        assert "Dataset(name=test-local-simple)" in rep_clean
        assert "Description: Simple math/geo" in rep_clean
        assert f"Records: {len(local_dataset_simple)}" in rep_clean
        assert "Structure: input: str, expected_output: str" in rep_clean # Based on first record structure
        assert "Datadog: Local only" in rep_clean
        assert "Changes:" not in rep_clean
        assert "URL:" not in rep_clean

    def test_repr_synced_no_changes(self, experiments_vcr, meals_workouts_dataset):
        """Test repr for a synced dataset with no changes."""
        dataset_name = meals_workouts_dataset.name
        # Pull the dataset again within this test's context to ensure it's fresh
        with experiments_vcr.use_cassette("test_dataset_pull_for_repr_test.yaml"):
            dataset = dne.Dataset.pull(dataset_name)

        rep = repr(dataset)
        rep_clean = self._strip_ansi(rep)

        assert f"Dataset(name={dataset_name})" in rep_clean
        assert f"Records: {len(dataset)}" in rep_clean
        # Structure based on the pulled data (string inputs/outputs for the cassette data)
        assert "Structure: input: str, expected_output: str" in rep_clean
        assert f"✓ Synced (v{dataset._datadog_dataset_version})" in rep_clean
        assert "Changes:" not in rep_clean
        # Check for URL presence and that the dataset ID appears within the URL part
        assert "URL: https://app." in rep_clean # Check prefix
        assert dataset._datadog_dataset_id in rep_clean # Check if the raw ID exists within the cleaned repr (likely in the encoded URL)

    def test_repr_unsynced_changes(self, experiments_vcr, meals_workouts_dataset):
        """Test repr for a synced dataset with pending local changes."""
        dataset_name = meals_workouts_dataset.name
        # Pull dataset for modification
        with experiments_vcr.use_cassette("test_dataset_pull_for_repr_unsynced_test.yaml"):
            dataset = dne.Dataset.pull(dataset_name)

        # Make changes - ensure structure matches the pulled dataset (string input/output, no metadata)
        dataset.add({"input": "new repr test input", "expected_output": "new repr response"})
        original_len = len(dataset._data) # Get length after add
        deleted_idx = -1
        if original_len > 1: # Ensure there's a record to delete
            deleted_idx = 0
            del dataset[0]
        updated_idx = -1
        if len(dataset._data) > 0: # Ensure there's a record to update
             updated_idx = 0 # Index 0 after potential deletion
             dataset[0] = {"input": "updated repr input", "expected_output": "updated repr response"}


        rep = repr(dataset)
        rep_clean = self._strip_ansi(rep)

        assert f"Dataset(name={dataset_name})" in rep_clean
        assert f"Records: {len(dataset)}" in rep_clean
        # Structure based on first record *after* modification (still string input/output)
        assert "Structure: input: str, expected_output: str" in rep_clean
        assert f"⚠ Unsynced changes (v{dataset._datadog_dataset_version})" in rep_clean
        # Update expected changes count based on actual modifications possible
        expected_changes = []
        if dataset._changes['added']: expected_changes.append(f"+{len(dataset._changes['added'])} added")
        if dataset._changes['deleted']: expected_changes.append(f"-{len(dataset._changes['deleted'])} deleted")
        if dataset._changes['updated']: expected_changes.append(f"~{len(dataset._changes['updated'])} updated")
        assert f"Changes: {', '.join(expected_changes)}" in rep_clean
        # Assert that URL is present and contains the ID even with unsynced changes if ID exists
        assert "URL: https://app." in rep_clean
        assert dataset._datadog_dataset_id in rep_clean # Check if the raw ID exists within the cleaned repr

    def test_repr_with_description(self, local_dataset_simple):
        """Test repr includes the description."""
        rep = repr(local_dataset_simple)
        rep_clean = self._strip_ansi(rep)
        assert "Description: Simple math/geo" in rep_clean

    def test_repr_without_description(self, sample_data_simple):
        """Test repr handles datasets without a description."""
        dataset = dne.Dataset(name="no-desc", data=sample_data_simple)
        rep = repr(dataset)
        rep_clean = self._strip_ansi(rep)
        assert "Description:" not in rep_clean
        assert "Dataset(name=no-desc)" in rep_clean
        assert "Records:" in rep_clean

    def test_repr_empty_dataset(self):
        """Test repr for an empty dataset (created locally)."""
        # Create then empty - Use valid keys for initial data
        dataset = dne.Dataset(name="empty-local", data=[{"input":"a", "expected_output":"b"}])
        del dataset[0]
        rep = repr(dataset)
        rep_clean = self._strip_ansi(rep)

        assert "Dataset(name=empty-local)" in rep_clean
        assert "Records: 0" in rep_clean
        assert "Structure:" not in rep_clean # No structure derivable when empty
        assert "Datadog: Local only" in rep_clean
        # Should show the deletion as a change until pushed/synced
        assert "Changes: -1 deleted" in rep_clean
