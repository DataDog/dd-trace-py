# Conditional Wrapping Optimization - Executive Summary

## The Question
**Should we only wrap locks when profiling is active to reduce overhead?**

## TL;DR Answer
**‚ùå Not feasible, but overhead is higher than expected and warrants OTHER optimizations.**

---

## Measured Performance Impact

| Configuration | Overhead per Lock Op | Impact @ 1M ops/sec |
|--------------|---------------------|---------------------|
| No profiling | baseline (59ns) | baseline |
| **0% capture** | **+597ns (10x)** | **+0.60 cores** ‚ö†Ô∏è |
| **1% capture (DEFAULT)** | **+641ns (11x)** | **+0.64 cores** ‚ö†Ô∏è |
| 100% capture | +5935ns (100x) | +5.9 cores üî• |

### Key Finding: Overhead is ~640ns per operation, NOT the 5-10ns initially estimated! 

---

## Feasibility Assessment

### ‚ùå Conditional Unwrapping: NOT FEASIBLE

**Idea:** Unwrap locks when profiler stops to eliminate overhead for pre-existing locks.

**Why it won't work:**
1. **No way to find locks** - They're stored everywhere (globals, instance vars, closures, locals)
2. **Identity preservation** - Locks used as dict keys, `lock is lock` checks would break
3. **Thread safety nightmare** - Race conditions during unwrapping
4. **High complexity** - Would need global registry, synchronization, state management

**Verdict:** ‚ùå Technical constraints make this impossible without major risks

---

## What IS Already Optimized ‚úÖ

The current implementation already handles these well:

1. ‚úÖ **Profiler not started** ‚Üí Zero overhead
2. ‚úÖ **Lock profiling disabled** ‚Üí Zero overhead  
3. ‚úÖ **New locks after profiler stops** ‚Üí Zero overhead
4. ‚úÖ **Low sampling rate** ‚Üí Only 1% of operations get full profiling

**The problem:** Locks created WHILE profiling is running keep ~640ns overhead even at 0% capture.

---

## Recommended Alternatives

### üéØ #1: Optimize Fast Path with Cython (HIGHEST IMPACT)

**Current bottleneck:** Python function call overhead (~600ns)

**Solution:** Rewrite hot path in Cython
```cython
cdef class _ProfiledLock:
    cdef inline acquire(self, *args, **kwargs):
        # Inlined capture check + direct delegation
```

**Estimated savings:** 85-90% reduction (650ns ‚Üí 50-100ns)  
**Complexity:** Medium  
**Risk:** Low

---

### üìñ #2: Better Documentation (IMMEDIATE)

**Document the actual overhead:**
```bash
# For lock-heavy applications (>100K lock ops/sec), consider:
DD_PROFILING_LOCK_ENABLED=false

# Or use per-module filtering:
DD_PROFILING_LOCK_EXCLUDE_MODULES=django,sqlalchemy,requests
```

**Impact table:**
| Lock Ops/Sec | CPU Overhead | Recommendation |
|--------------|--------------|----------------|
| < 10K | ~6ms/sec | ‚úÖ Keep enabled |
| 10K - 100K | 6-60ms/sec | ‚ö†Ô∏è Monitor |
| 100K - 1M | 60-640ms/sec | ‚ö†Ô∏è Consider disabling |
| > 1M | > 640ms/sec | üî• Disable immediately |

---

### üîß #3: Per-Module Filtering (MEDIUM EFFORT)

**Add configuration:**
```python
DD_PROFILING_LOCK_EXCLUDE_MODULES=django.db,sqlalchemy.pool,urllib3
# Don't wrap locks from these modules
```

**Benefits:**
- Reduce overhead for framework locks
- Keep profiling for application locks
- User-configurable tradeoff

---

### üß† #4: Adaptive Sampling (FUTURE)

**Idea:** Focus profiling on actually contended locks

```python
class _AdaptiveSampler:
    def should_capture(self, lock):
        if lock.contention_count > THRESHOLD:
            return True  # Always sample hot locks
        else:
            return rarely()  # Minimal sampling for cold locks
```

**Benefits:**
- Better data quality (more samples from important locks)
- Less overhead for uncontended locks
- Automatic optimization

---

## Bottom Line

### What NOT to do:
- ‚ùå Don't pursue conditional unwrapping (not feasible)
- ‚ùå Don't add collector status checks (makes it slower)

### What TO do:
1. üéØ **Rewrite hot path in Cython** ‚Üí 85-90% overhead reduction
2. üìñ **Document overhead & provide config options** ‚Üí Immediate relief for affected users
3. üîß **Add per-module filtering** ‚Üí User control over overhead
4. üß† **Explore adaptive sampling** ‚Üí Future optimization

### Estimated ROI:

| Optimization | Effort | Savings | Timeline |
|-------------|--------|---------|----------|
| Cython fast path | Medium | 85-90% | 1-2 months |
| Documentation | Low | Varies | Immediate |
| Module filtering | Medium | 50-90% | 2-4 weeks |
| Adaptive sampling | High | 30-70% | 3-6 months |

---

## Testing

Run the measurement script to see actual overhead on your system:
```bash
source venv/bin/activate
python measure_lock_overhead.py
```

See `CONDITIONAL_WRAPPING_ANALYSIS.md` for full technical details.

