name: System Tests

on:
  push:
    branches:
      - 2.x
  pull_request:
  workflow_dispatch: {}
  schedule:
    - cron: '00 04 * * 2-6'

jobs:
  needs-run:
    runs-on: ubuntu-latest
    outputs:
      outcome: ${{ steps.run_needed.outcome }}
    steps:
      - uses: actions/checkout@v3
      - id: run_needed
        name: Check if run is needed
        run:  |
          git fetch origin ${{ github.event.pull_request.base.sha }}
          export PATHS=$(git diff --name-only HEAD ${{ github.event.pull_request.base.sha }})
          python -c "import os,sys,fnmatch;sys.exit(not bool([_ for pattern in {'ddtrace/*', 'setup*', 'pyproject.toml', '.github/workflows/system-tests.yml'} for _ in fnmatch.filter(os.environ['PATHS'].splitlines(), pattern)]))"
        continue-on-error: true

  system-tests:
    runs-on: ubuntu-latest
    needs: needs-run
    if: needs.needs-run.outputs.outcome == 'success' || github.event_name == 'schedule'
    strategy:
      matrix:
        include:
          - weblog-variant: flask-poc
          - weblog-variant: uwsgi-poc
          - weblog-variant: django-poc
        #   runs django-poc for 3.12
          - weblog-variant: python3.12
      fail-fast: false
    env:
      TEST_LIBRARY: python
      WEBLOG_VARIANT: ${{ matrix.weblog-variant }}
      # system-tests requires an API_KEY, but it does not have to be a valid key, as long as we don't run a scenario
      # that make assertion on backend data. Using a fake key allow to run system tests on PR originating from forks.
      # If ever it's needed, a valid key exists in the repo, using ${{ secrets.DD_API_KEY }}
      DD_API_KEY: 1234567890abcdef1234567890abcdef
      CMAKE_BUILD_PARALLEL_LEVEL: 12
    steps:
      - name: Setup python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
  
      - name: Checkout system tests
        uses: actions/checkout@v3
        with:
          repository: 'DataDog/system-tests'

      - name: Checkout dd-trace-py
        uses: actions/checkout@v3
        with:
          path: 'binaries/dd-trace-py'
          fetch-depth: 0

      - name: Build
        run: ./build.sh

      - name: Run
        run: ./run.sh

      - name: Run REMOTE_CONFIG_MOCKED_BACKEND_ASM_FEATURES
        run: ./run.sh REMOTE_CONFIG_MOCKED_BACKEND_ASM_FEATURES

      - name: Run REMOTE_CONFIG_MOCKED_BACKEND_LIVE_DEBUGGING
        run: ./run.sh REMOTE_CONFIG_MOCKED_BACKEND_LIVE_DEBUGGING

      - name: Run REMOTE_CONFIG_MOCKED_BACKEND_ASM_DD
        run: ./run.sh REMOTE_CONFIG_MOCKED_BACKEND_ASM_DD

      - name: Run APPSEC_MISSING_RULES
        run: ./run.sh APPSEC_MISSING_RULES

      - name: Run APPSEC_CUSTOM_RULES
        run: ./run.sh APPSEC_CUSTOM_RULES

      - name: Run APPSEC_CORRUPTED_RULES
        run: ./run.sh APPSEC_CORRUPTED_RULES

      - name: Run APPSEC_RULES_MONITORING_WITH_ERRORS
        run: ./run.sh APPSEC_RULES_MONITORING_WITH_ERRORS

      - name: Run APPSEC_BLOCKING
        run: ./run.sh APPSEC_BLOCKING

      - name: Run APPSEC_DISABLED
        run: ./run.sh APPSEC_DISABLED

      - name: Run APPSEC_LOW_WAF_TIMEOUT
        run: ./run.sh APPSEC_LOW_WAF_TIMEOUT

      - name: Run APPSEC_CUSTOM_OBFUSCATION
        run: ./run.sh APPSEC_CUSTOM_OBFUSCATION

      - name: Run APPSEC_RATE_LIMITER
        run: ./run.sh APPSEC_RATE_LIMITER

      - name: Run APPSEC_BLOCKING_FULL_DENYLIST
        run: ./run.sh APPSEC_BLOCKING_FULL_DENYLIST

      - name: Run APPSEC_REQUEST_BLOCKING
        run: ./run.sh APPSEC_REQUEST_BLOCKING

      - name: Run APPSEC_RUNTIME_ACTIVATION
        run: ./run.sh APPSEC_RUNTIME_ACTIVATION

      - name: Run APPSEC_WAF_TELEMETRY
        run: ./run.sh APPSEC_WAF_TELEMETRY

      - name: Run SAMPLING
        run: ./run.sh SAMPLING

      # even on failures, we want to have artifact to be able to investigate
      # The compress step speed up a lot the upload artifact process
      - name: Compress artifact
        run: tar -czvf artifact.tar.gz $(ls | grep logs)

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: logs_${{ matrix.weblog-variant }}
          path: artifact.tar.gz

  parametric:
    runs-on: ubuntu-latest
    needs: needs-run
    if: needs.needs-run.outputs.outcome == 'success' || github.event_name == 'schedule'
    env:
      TEST_LIBRARY: python
      PYTHON_DDTRACE_PACKAGE: git+https://github.com/Datadog/dd-trace-py.git@${{ github.sha }}
    steps:
      - name: Checkout system tests
        uses: actions/checkout@v3
        with:
          repository: 'DataDog/system-tests'

      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Build
        run: ./build.sh -i runner

      - name: Run
        run: ./run.sh PARAMETRIC

      - name: Compress artifact
        run: tar -czvf artifact.tar.gz $(ls | grep logs)

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: logs_parametric
          path: artifact.tar.gz
