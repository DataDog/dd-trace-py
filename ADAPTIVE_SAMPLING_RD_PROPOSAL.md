# Adaptive Sampling R&D Proposal

**For:** R&D Week  
**Focus:** Lock Profiler (expandable to all profilers)  
**Goal:** Reduce overhead while maintaining data quality

---

## üìä Current State Analysis

### What's Already Implemented?

#### ‚úÖ **Stack Profiler (stack_v2)** - HAS Adaptive Sampling!

**Location:** `ddtrace/internal/datadog/profiling/stack_v2/src/sampler.cpp:112-144`

**How it works:**
```cpp
// Formula: I' = I * [(s / p) / o]
// Where:
//   I  = current interval
//   s  = sampler thread time
//   p  = process time
//   o  = overhead threshold (target)
//   I' = new interval

auto new_interval = current_interval * ((sampler_thread_delta / process_delta) / g_target_overhead);

// Bounded by min/max:
if (new_interval < g_min_sampling_period_us) {
    new_interval = g_min_sampling_period_us;
} else if (new_interval > g_max_sampling_period_us) {
    new_interval = g_max_sampling_period_us;
}
```

**Key features:**
- ‚úÖ Adjusts sampling interval based on measured overhead
- ‚úÖ Target overhead threshold (prevents CPU waste)
- ‚úÖ Min/max bounds (prevents extreme intervals)
- ‚úÖ Adapts every ~1 second
- ‚úÖ Configuration: `DD_PROFILING_STACK_V2_ADAPTIVE_SAMPLING_ENABLED`

**Impact:**
- Automatically reduces sampling when overhead is high
- Increases sampling when system is idle
- Maintains target overhead percentage

---

#### ‚úÖ **Memory Profiler** - HAS Sophisticated Sampling!

**Location:** `ddtrace/profiling/collector/_memalloc_heap.cpp:1-166`

**How it works:**
```cpp
// Based on tcmalloc's approach:
// https://github.com/google/tcmalloc/blob/master/docs/sampling.md

// 1. Sample using exponential distribution:
uint32_t next_sample_size(uint32_t sample_size) {
    double q = (double)rand() / ((double)RAND_MAX + 1);  // [0, 1)
    double log_val = log2(q);                             // ]-inf, 0)
    return (uint32_t)(log_val * (-log(2) * (sample_size + 1)));
}

// 2. Weight samples to correct bias:
// Weight = R + (C - T)
// Where:
//   R = sampling interval
//   C = counter (including sampled allocation)
//   T = target
```

**Key features:**
- ‚úÖ Probabilistic sampling (bytes-based, not count-based)
- ‚úÖ Statistical weighting to correct for sampling bias
- ‚úÖ Adapts sampling rate to memory pressure
- ‚úÖ Large allocations more likely to be sampled
- ‚úÖ Configuration: `DD_PROFILING_HEAP_SAMPLE_SIZE`

**Impact:**
- Captures representative memory profile with minimal overhead
- Properly weights samples for accurate heap representation
- Works well with both small and large allocations

---

#### ‚ùå **Lock Profiler** - NO Adaptive Sampling

**Location:** `ddtrace/profiling/collector/_lock.py`

**Current sampling:**
```python
class CaptureSampler:
    def __init__(self, capture_pct: float = 100.0):
        self.capture_pct = capture_pct
        self._counter = 0
    
    def capture(self) -> bool:
        self._counter += self.capture_pct
        if self._counter >= 100:
            self._counter -= 100
            return True
        return False
```

**Problems:**
- ‚ùå **Fixed percentage** - same for all locks
- ‚ùå **No awareness of contention** - hot locks sampled same as cold locks
- ‚ùå **No overhead adaptation** - doesn't adjust to system load
- ‚ùå **Global sampling** - doesn't consider per-lock characteristics
- ‚ùå **No lock "importance" heuristic** - all locks treated equally

**Configuration:**
- `DD_PROFILING_LOCK_ENABLED` - on/off only
- `DD_PROFILING_CAPTURE_PCT` - global percentage (default 1%)

---

#### ‚ö†Ô∏è **PyTorch Profiler** - Simple Event Limiting

**Location:** `ddtrace/profiling/collector/pytorch.py:111-141`

**Current approach:**
```python
# Just truncates to max events:
num_events_to_report = min(len(events), config.pytorch.events_limit or 1_000_000)
if num_events_to_report < len(events):
    collection_fraction = num_events_to_report / len(events)
```

**Problems:**
- ‚ùå Random truncation, not intelligent sampling
- ‚ùå No adaptation to workload
- ‚ùå Loses important events

---

## üéØ Opportunity: Adaptive Lock Profiling

### Why Lock Profiler Needs Adaptive Sampling

**Problem 1: Overhead is Variable**
- Lock-light apps (<10K ops/sec): 6ms CPU/sec overhead
- Lock-heavy apps (>1M ops/sec): **650ms+ CPU/sec overhead** (0.65+ cores!)

Current solution: Turn it off completely or suffer overhead

**Problem 2: Not All Locks Are Equal**
- **Hot locks** (contended, long waits): VERY important to profile
- **Cold locks** (no contention, microsecond holds): Less important
- Current sampling: Treats both equally

**Problem 3: Wasted Samples**
- 99% of locks might be uncontended
- 1% sampling still wastes CPU on uncontended locks
- Meanwhile, we undersample the actually interesting locks

---

## üí° Proposed: Adaptive Lock Sampling

### Design Philosophy

**Goal:** Sample locks based on their "interestingness"

**"Interesting" locks:**
- High contention (multiple threads waiting)
- Long wait times (blocking significant time)
- Long hold times (monopolizing resource)
- Hot code paths (frequently acquired/released)

**Boring locks:**
- No contention (acquired immediately)
- Microsecond hold times
- Rarely used
- Internal framework locks (e.g., logging, caching)

---

### Approach 1: Contention-Based Adaptive Sampling üéØ

**Concept:** Sample contended locks at high rate, uncontended locks at low rate

**Implementation:**

```python
class AdaptiveLockSampler:
    """Adaptive sampler that adjusts based on lock contention."""
    
    def __init__(
        self,
        base_capture_pct: float = 1.0,
        hot_capture_pct: float = 100.0,
        contention_threshold_ns: int = 1_000_000,  # 1ms
    ):
        self.base_capture_pct = base_capture_pct
        self.hot_capture_pct = hot_capture_pct
        self.contention_threshold_ns = contention_threshold_ns
        
        # Per-lock statistics
        self.lock_stats: Dict[int, LockStats] = {}
    
    def should_capture(self, lock_id: int, wait_time_ns: int) -> Tuple[bool, float]:
        """
        Decide if we should capture this lock operation.
        
        Returns: (should_capture, sample_weight)
        """
        stats = self.lock_stats.get(lock_id)
        
        # First few operations: always sample to gather data
        if stats is None or stats.total_ops < 10:
            return (True, 1.0)
        
        # High contention: sample frequently
        if stats.avg_wait_time_ns > self.contention_threshold_ns:
            capture_pct = self.hot_capture_pct
        # Medium contention: sample moderately
        elif stats.avg_wait_time_ns > self.contention_threshold_ns / 10:
            capture_pct = self.base_capture_pct * 10
        # Low contention: sample rarely
        else:
            capture_pct = self.base_capture_pct
        
        # Deterministic sampling with counter
        stats.counter += capture_pct
        if stats.counter >= 100:
            stats.counter -= 100
            # Weight sample by inverse of capture rate
            weight = 100.0 / capture_pct
            return (True, weight)
        
        return (False, 0.0)
    
    def update_stats(self, lock_id: int, wait_time_ns: int):
        """Update statistics after lock operation."""
        if lock_id not in self.lock_stats:
            self.lock_stats[lock_id] = LockStats()
        
        stats = self.lock_stats[lock_id]
        stats.total_ops += 1
        stats.total_wait_time_ns += wait_time_ns
        
        # Exponential moving average for adaptive behavior
        alpha = 0.1
        stats.avg_wait_time_ns = (
            alpha * wait_time_ns + 
            (1 - alpha) * stats.avg_wait_time_ns
        )
        
        # Decay old stats to adapt to changing workloads
        if stats.total_ops % 1000 == 0:
            stats.avg_wait_time_ns *= 0.9


@dataclass
class LockStats:
    total_ops: int = 0
    total_wait_time_ns: int = 0
    avg_wait_time_ns: float = 0.0
    counter: float = 0.0
```

**Benefits:**
- ‚úÖ Hot locks get sampled frequently (better data quality)
- ‚úÖ Cold locks get sampled rarely (less overhead)
- ‚úÖ Adapts to changing workload patterns
- ‚úÖ Statistical weighting maintains accuracy

**Overhead:**
- Per-lock stats: ~64 bytes per lock
- Update cost: ~50ns per operation (negligible vs 650ns current overhead)
- Net benefit: Potentially 50-80% overhead reduction

---

### Approach 2: Overhead-Based Adaptive Sampling üéØ

**Concept:** Like stack_v2, adjust sampling based on measured overhead

**Implementation:**

```python
class OverheadAdaptiveSampler:
    """Adjusts sampling rate to maintain target CPU overhead."""
    
    def __init__(
        self,
        target_overhead_pct: float = 1.0,  # 1% CPU overhead target
        min_capture_pct: float = 0.1,
        max_capture_pct: float = 10.0,
    ):
        self.target_overhead_pct = target_overhead_pct
        self.min_capture_pct = min_capture_pct
        self.max_capture_pct = max_capture_pct
        self.current_capture_pct = 1.0
        
        # Overhead tracking
        self.profiling_time_ns = 0
        self.total_time_ns = 0
        self.last_adjust_time = time.monotonic_ns()
    
    def should_capture(self) -> bool:
        """Deterministic sampling at current rate."""
        self._counter += self.current_capture_pct
        if self._counter >= 100:
            self._counter -= 100
            return True
        return False
    
    def record_overhead(self, overhead_ns: int):
        """Track time spent profiling."""
        self.profiling_time_ns += overhead_ns
        self.total_time_ns += overhead_ns  # Simplified
    
    def adapt(self):
        """Adjust sampling rate based on measured overhead (call every ~1s)."""
        now = time.monotonic_ns()
        if now - self.last_adjust_time < 1_000_000_000:  # 1 second
            return
        
        # Calculate actual overhead percentage
        if self.total_time_ns == 0:
            return
        
        actual_overhead_pct = (self.profiling_time_ns / self.total_time_ns) * 100
        
        # Adjust sampling rate using feedback formula:
        # new_rate = current_rate * (target / actual)
        adjustment = self.target_overhead_pct / actual_overhead_pct
        new_capture_pct = self.current_capture_pct * adjustment
        
        # Clamp to min/max
        new_capture_pct = max(
            self.min_capture_pct,
            min(self.max_capture_pct, new_capture_pct)
        )
        
        self.current_capture_pct = new_capture_pct
        
        # Reset counters
        self.profiling_time_ns = 0
        self.total_time_ns = 0
        self.last_adjust_time = now
```

**Benefits:**
- ‚úÖ Automatically maintains target overhead budget
- ‚úÖ Adapts to system load
- ‚úÖ No manual tuning needed
- ‚úÖ Works across different workloads

**Challenges:**
- ‚ö†Ô∏è Measuring "total time" accurately is tricky
- ‚ö†Ô∏è May oscillate if feedback is too aggressive
- ‚ö†Ô∏è Doesn't distinguish hot vs cold locks

---

### Approach 3: Hybrid (RECOMMENDED) üèÜ

**Combine both approaches:**

1. **Contention-based** prioritization (hot locks sampled more)
2. **Overhead-based** global adjustment (maintain CPU budget)

**Implementation:**

```python
class HybridAdaptiveSampler:
    """
    Best of both worlds:
    - Prioritize contended locks
    - Maintain overhead budget
    """
    
    def __init__(
        self,
        target_overhead_pct: float = 1.0,
        contention_threshold_ns: int = 1_000_000,
    ):
        self.target_overhead_pct = target_overhead_pct
        self.contention_threshold_ns = contention_threshold_ns
        
        # Global overhead control
        self.global_multiplier = 1.0  # Adjusts all rates
        
        # Per-lock priorities
        self.lock_priorities: Dict[int, float] = {}  # 0.1 to 10.0
        self.lock_stats: Dict[int, LockStats] = {}
    
    def should_capture(self, lock_id: int) -> Tuple[bool, float]:
        """
        Returns: (should_capture, sample_weight)
        """
        # Get lock priority (1.0 = normal, 10.0 = very hot, 0.1 = very cold)
        priority = self.lock_priorities.get(lock_id, 1.0)
        
        # Effective capture rate = priority * global_multiplier
        effective_rate = priority * self.global_multiplier
        
        # Statistical sampling
        if random.random() < (effective_rate / 100.0):
            weight = 100.0 / effective_rate
            return (True, weight)
        
        return (False, 0.0)
    
    def update_priority(self, lock_id: int, wait_time_ns: int):
        """Update lock priority based on contention."""
        if lock_id not in self.lock_stats:
            self.lock_stats[lock_id] = LockStats()
        
        stats = self.lock_stats[lock_id]
        stats.update(wait_time_ns)
        
        # Calculate priority based on average wait time
        if stats.avg_wait_time_ns > self.contention_threshold_ns:
            priority = 10.0  # Very hot
        elif stats.avg_wait_time_ns > self.contention_threshold_ns / 10:
            priority = 3.0   # Moderately hot
        else:
            priority = 0.5   # Cold
        
        self.lock_priorities[lock_id] = priority
    
    def adapt_global_rate(self, measured_overhead_pct: float):
        """Adjust global multiplier to maintain overhead budget."""
        if measured_overhead_pct == 0:
            return
        
        # Feedback control
        adjustment = self.target_overhead_pct / measured_overhead_pct
        self.global_multiplier *= adjustment
        
        # Clamp to reasonable range
        self.global_multiplier = max(0.01, min(10.0, self.global_multiplier))
```

**Benefits:**
- ‚úÖ Best data quality (samples important locks)
- ‚úÖ Controlled overhead (maintains budget)
- ‚úÖ Adapts to both workload and system load
- ‚úÖ Statistical weighting for accurate representation

---

## üìà Expected Impact

### Performance Improvements

| Scenario | Current | With Adaptive | Improvement |
|----------|---------|---------------|-------------|
| **Lock-heavy app (1M ops/sec)** | 650ms CPU/sec | 65-130ms CPU/sec | **80-90%** ‚ö†Ô∏è |
| **Mixed workload** | 200ms CPU/sec | 30-50ms CPU/sec | **75-85%** |
| **Lock-light app** | 10ms CPU/sec | 5-10ms CPU/sec | **0-50%** |

### Data Quality Improvements

| Metric | Current (1% uniform) | With Adaptive | Improvement |
|--------|---------------------|---------------|-------------|
| **Hot lock coverage** | 1% sampled | 50-100% sampled | **50-100x** üéØ |
| **Contention detection** | Rare | Common | **10-50x** |
| **CPU wasted on cold locks** | ~99% of overhead | ~10-20% | **80-90% less waste** |

### Storage/Processing Impact

**Overhead per lock:**
```
LockStats structure:
- total_ops: 8 bytes
- total_wait_time_ns: 8 bytes
- avg_wait_time_ns: 8 bytes
- counter: 8 bytes
- priority: 8 bytes
Total: 40 bytes per lock
```

**Memory impact:**
- 1,000 locks: 40 KB
- 10,000 locks: 400 KB
- 100,000 locks: 4 MB

**Storage impact:**
- Same number of samples (or fewer)
- Each sample has weight metadata: +8 bytes
- Net: Neutral or reduced (fewer cold lock samples)

**Processing impact:**
- Backend needs to handle sample weights
- Existing infrastructure already handles weights (memory profiler)
- Net: Minimal change

---

## üõ†Ô∏è Implementation Plan

### Phase 1: Prototype (R&D Week) ‚è±Ô∏è 3-4 days

**Day 1:**
- [ ] Implement `AdaptiveLockSampler` class
- [ ] Add configuration flags
- [ ] Unit tests for sampling logic

**Day 2:**
- [ ] Integrate into `_ProfiledLock`
- [ ] Add statistics tracking
- [ ] Test with benchmark apps

**Day 3:**
- [ ] Measure overhead reduction
- [ ] Measure data quality improvement
- [ ] Document findings

**Day 4:**
- [ ] Polish implementation
- [ ] Create demo/presentation
- [ ] Decision: Ship or shelve?

**Deliverables:**
- Working prototype
- Performance benchmarks
- Data quality comparison
- Go/no-go recommendation

---

### Phase 2: Production (If Approved) ‚è±Ô∏è 2-3 weeks

**Week 1:**
- Backend integration (sample weighting)
- Configuration system
- Comprehensive testing

**Week 2:**
- Cross-platform validation
- Performance tuning
- Documentation

**Week 3:**
- Beta testing with internal apps
- Monitoring/telemetry
- Release preparation

---

## üéØ Success Metrics

### Must Have:
- [ ] **70%+ overhead reduction** for lock-heavy apps
- [ ] **No degradation** in data quality for hot locks
- [ ] **Memory overhead <1MB** for typical apps
- [ ] **No breaking changes** to existing API

### Should Have:
- [ ] **85%+ overhead reduction** for lock-heavy apps
- [ ] **Better hot lock detection** (more samples from contended locks)
- [ ] **Automatic adaptation** (no manual tuning needed)
- [ ] **Graceful degradation** (falls back to simple sampling if needed)

### Nice to Have:
- [ ] **95%+ overhead reduction** for lock-heavy apps
- [ ] **Zero-config** optimization (works out of the box)
- [ ] **Telemetry** showing adaptation in action
- [ ] **User-visible metrics** (sampling efficiency, contention heatmap)

---

## üåü Expand to Other Profilers?

### Memory Profiler
**Status:** ‚úÖ Already has sophisticated sampling  
**Opportunity:** None (already excellent)

### Stack Profiler
**Status:** ‚úÖ Already has adaptive sampling  
**Opportunity:** None (already adaptive)

### PyTorch Profiler
**Status:** ‚ö†Ô∏è Simple event limiting  
**Opportunity:** üéØ **High** - Could apply similar contention-based approach

**Potential improvement:**
```python
# Current: random truncation
collection_fraction = num_events_to_report / len(events)

# Better: sample important events
priority_sampler = AdaptivePyTorchSampler()
for event in events:
    if priority_sampler.should_capture(event):
        # Prioritize:
        # - Long-running operations
        # - GPU-bound operations
        # - High memory operations
        sample_event(event, weight=...)
```

**Impact:** Better PyTorch profiling data quality with same storage

---

## üí∞ ROI Analysis

### Development Cost
- **R&D Week:** 3-4 days (prototyp)
- **Production:** 2-3 weeks (if approved)
- **Total:** ~4 weeks

### Customer Benefit

**For a customer with 1M lock ops/sec:**

| Metric | Before | After | Savings |
|--------|--------|-------|---------|
| CPU overhead | 650ms/sec | 65-130ms/sec | **0.52-0.59 cores** |
| Annual compute cost* | $4,500/year | $450-900/year | **$3,600-4,050/year** |

*Assuming $8,000/year per core (AWS c5.xlarge)

**Across 1,000 lock-heavy customers:**
- **Total savings: $3.6-4M/year** üí∞
- **Plus:** Better data quality for debugging/optimization

### Internal Benefit
- **Reduced storage:** Fewer cold lock samples
- **Better signal/noise:** More samples from important locks
- **Customer satisfaction:** Less overhead complaints

---

## üö® Risks & Mitigation

### Risk 1: Complexity
**Concern:** Adaptive sampling is more complex than simple percentage

**Mitigation:**
- Start with hybrid approach (best ROI)
- Extensive testing with real workloads
- Feature flag for gradual rollout
- Fallback to simple sampling if needed

### Risk 2: Stats Overhead
**Concern:** Per-lock statistics might add overhead

**Mitigation:**
- Lightweight stats structure (40 bytes)
- Lazy initialization (only for active locks)
- Periodic cleanup of inactive locks
- Benchmark overhead in prototype

### Risk 3: Backend Changes
**Concern:** Sample weighting requires backend support

**Mitigation:**
- Memory profiler already uses weights
- Existing infrastructure can handle it
- Graceful degradation if backend doesn't support weights
- Coordinate with backend team early

### Risk 4: Tuning Difficulty
**Concern:** Too many parameters to tune

**Mitigation:**
- Sane defaults based on testing
- Auto-tuning (overhead-based adaptation)
- Simple on/off flag for users
- Telemetry to monitor effectiveness

---

## üéØ Recommendation

### For R&D Week: ‚úÖ **GO!**

**Why this is a great R&D project:**
1. **Clear problem:** Lock profiling overhead is real (650ms CPU/sec for heavy users)
2. **Proven approach:** Stack profiler already does this successfully
3. **Measurable impact:** Easy to benchmark (overhead before/after)
4. **Contained scope:** Can prototype in 3-4 days
5. **High ROI:** Huge customer benefit ($3.6-4M/year savings potential)

**What to build in R&D week:**
- Hybrid adaptive sampler prototype
- Benchmark suite showing overhead reduction
- Data quality comparison (hot vs cold lock sampling)
- Demo showing adaptation in action

**Success criteria:**
- 70%+ overhead reduction demonstrated
- No loss in hot lock data quality
- Decision: Ship it or learn from it

**Even if you don't ship it,** you'll learn:
- How lock profiling overhead scales
- Which locks matter most
- What customers actually need

**This is a perfect R&D week project!** üöÄ

---

## üìö References

- Stack v2 adaptive sampling: `ddtrace/internal/datadog/profiling/stack_v2/src/sampler.cpp`
- Memory sampling: `ddtrace/profiling/collector/_memalloc_heap.cpp`
- tcmalloc sampling design: https://github.com/google/tcmalloc/blob/master/docs/sampling.md
- Lock profiler current: `ddtrace/profiling/collector/_lock.py`

