---
features:
  - |
    LLM Observability: This introduces an integration with the [RAGAS](https://docs.ragas.io/en/stable/) evaluation framework to continuously monitor 
                      the performance of context-augmented LLM generations in production.

                      The integration supports evaluating LLM inferences with the following RAGAS metrics:
                      - [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/): measures if the LLM response is faithful to the provided context.
                      - [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_relevance/): measures how relevant the LLM response is to the user input.
                      - [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/):  measures how effectively the context is used in the generated response.

                      # (TODI): UPDATE TO CORRECT LINK LATER!!!
                      For more information, please see the [RAGAS Integration documentation](https://docs.datadoghq.com/llm_observability/submit_evaluations/ragas_integration).
