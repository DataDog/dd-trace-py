stages:
  - deploy
  - benchmarks
  - benchmarks-pr-comment

include: ".gitlab/benchmarks.yml"

variables:
  DOWNSTREAM_BRANCH:
    value: "master"
    description: "Run a specific datadog-reliability-env branch downstream"
  FORCE_TRIGGER:
    value: "false"
    description: "Set to true to override rules in the reliability-env pipeline (e.g. override 'only deploy master')"
  DOWNSTREAM_MBP_BRANCH:
    value: "dd-trace-py"
    description: "Run a specific relenv-microbenchmarking-platform branch downstream"


.common: &common
  tags: [ "runner:main", "size:large" ]

deploy_to_reliability_env:
  stage: deploy
  when: on_success
  trigger:
    project: DataDog/apm-reliability/datadog-reliability-env
    branch: $DOWNSTREAM_BRANCH
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME
    UPSTREAM_BRANCH: $CI_COMMIT_REF_NAME
    UPSTREAM_COMMIT_SHA: $CI_COMMIT_SHA
    FORCE_TRIGGER: $FORCE_TRIGGER

deploy_to_di_backend:automatic:
  stage: deploy
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: on_success
  trigger:
    project: DataDog/debugger-backend
    branch: main
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME
    UPSTREAM_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA
    UPSTREAM_PIPELINE_ID: $CI_PIPELINE_ID
    UPSTREAM_TAG: $CI_COMMIT_TAG
    UPSTREAM_PACKAGE_JOB: build
    
deploy_to_di_backend:manual:
  stage: deploy
  rules:
    - when: manual
      allow_failure: true
  trigger:
    project: DataDog/debugger-backend
    branch: main
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME
    UPSTREAM_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA
    UPSTREAM_PIPELINE_ID: $CI_PIPELINE_ID
    UPSTREAM_COMMIT_AUTHOR: $CI_COMMIT_AUTHOR
    UPSTREAM_TAG: $CI_COMMIT_TAG
    UPSTREAM_PACKAGE_JOB: build

deploy_to_docker_registries:
  stage: deploy
  rules:
    - if: '$POPULATE_CACHE'
      when: never
    - if: '$CI_COMMIT_TAG =~ /^v.*/'
      when: on_success
    - when: manual
      allow_failure: true
  trigger:
    project: DataDog/public-images
    branch: main
    strategy: depend
  variables:
    IMG_SOURCES: ghcr.io/datadog/dd-trace-py/dd-lib-python-init:$CI_COMMIT_TAG
    IMG_DESTINATIONS: dd-lib-python-init:$CI_COMMIT_TAG
    IMG_SIGNING: "false"
    # Wait 4 hours to trigger the downstream job.
    # This is a work-around since there isn't a way to trigger
    # Gitlab from the Github workflow (build_deploy.yml:upload_pypi).
    #
    # The caveat here is that if there is a failure to build to PyPI and it
    # isn't fixed in the retry period then this job will fail and images will
    # not be published.
    RETRY_DELAY: 14400
    RETRY_COUNT: 3

deploy_latest_tag_to_docker_registries:
  stage: deploy
  rules:
    - if: '$POPULATE_CACHE'
      when: never
    - if: '$CI_COMMIT_TAG =~ /^v.*/'
      when: on_success
    - when: manual
      allow_failure: true
  trigger:
    project: DataDog/public-images
    branch: main
    strategy: depend
  variables:
    IMG_SOURCES: ghcr.io/datadog/dd-trace-py/dd-lib-python-init:$CI_COMMIT_TAG
    IMG_DESTINATIONS: dd-lib-python-init:latest
    IMG_SIGNING: "false"
    # See above note in the `deploy_to_docker_registries` job.
    RETRY_DELAY: 14400
    RETRY_COUNT: 3
