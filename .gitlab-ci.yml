stages:
  - setup
  - package
  - tests
  - shared-pipeline
  - benchmarks
  - release

variables:
  REPO_LANG: python # "python" is used everywhere rather than "py"
  REPO_NOTIFICATION_CHANNEL: "#apm-python-release"
  RELEASE_ALLOW_TEST_FAILURES: false
  RELEASE_ALLOW_BENCHMARK_FAILURES: false
  # VPA Template configuration
  DD_VPA_TEMPLATE: "vpa-template-cpu-p70-10percent-2x-oom-min-cap"
  # CI_DEBUG_SERVICES: "true"
  # Automatically managed, use scripts/update-system-tests-version to update
  SYSTEM_TESTS_REF: "30e17ba7009b84998c0ada3b3a17f39c0037faba"

default:
  interruptible: true

# trigger new commit cancel
workflow:
  auto_cancel:
    on_new_commit: interruptible
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
      auto_cancel:
        on_new_commit: none
    - if: $CI_COMMIT_BRANCH =~ /^[0-9]+\.[0-9]+$/
      auto_cancel:
        on_new_commit: none
    - when: always

include:
  - local: ".gitlab/one-pipeline.locked.yml"
  - local: ".gitlab/services.yml" # Include early so others can use the definitions
  - local: ".gitlab/package.yml"
  - local: ".gitlab/release.yml"
  - local: ".gitlab/testrunner.yml"
  - local: ".gitlab/multi-os-tests.yml"
  - local: ".gitlab/benchmarks/serverless.yml"
  - local: ".gitlab/native.yml"


# Expose the following variables to the rest of the pipeline
#   GH_PR_NUMBER: The GitHub PR number if there is an open PR for this commit, empty otherwise
#   GH_PR_TITLE: The GitHub PR title if there is an open PR for this commit, empty otherwise
#   HAS_OPEN_PR: "true" if there is an open PR for this commit, "false" otherwise
#   IS_MAIN_BRANCH: "true" if the current branch is main
#   IS_RELEASE_BRANCH: "true" if the current branch is a release branch (e.g., "1.2"), "false" otherwise
#   IS_RELEASE: "true" if the current commit is a release tag (e.g., "v1.2.3"), "false" otherwise
#   IS_MERGE_QUEUE: "true" if the current branch is a merge queue branch (e.g., starts with "gh-readonly-queue/"), "false" otherwise
pipeline variables:
  image: registry.ddbuild.io/images/dd-octo-sts-ci-base:2025.06-1
  tags: [ "arch:amd64" ]
  stage: setup
  id_tokens:
    DDOCTOSTS_ID_TOKEN:
      aud: dd-octo-sts
  variables:
    GIT_STRATEGY: none
    GH_REPO: DataDog/dd-trace-py
  script:
    - |
      if [ -z ${GH_TOKEN} ]
      then
        # Use dd-octo-sts to get GitHub token
        dd-octo-sts token --scope DataDog/dd-trace-py --policy gitlab.github-access.read > token
        gh auth login --with-token < token
        rm token
      fi
    - |
      # Prevent git operation errors:
      #   failed to determine base repo: failed to run git: fatal: detected dubious ownership in repository at ...
      git config --global --add safe.directory "${CI_PROJECT_DIR}"
    - |
      # Determine if we have an open GitHub PR for this commit
      GH_RESULT=$(gh pr list --state open --search "${CI_COMMIT_SHA}" --json title,number --jq '.[0].title,.[0].number' || echo "")
      GH_PR_NUMBER=$(echo $GH_RESULT | awk 'NR==2')
      GH_PR_TITLE=$(echo $GH_RESULT | awk 'NR==1')
      echo "GH_PR_NUMBER=${GH_PR_NUMBER}" | tee -a workflow.env
      echo "GH_PR_TITLE=${GH_PR_TITLE}" | tee -a workflow.env
      echo "HAS_OPEN_PR=$(if [ -z "${GH_PR_NUMBER}" ]; then echo "false"; else echo "true"; fi)" | tee -a workflow.env
      echo "IS_MAIN_BRANCH=$(if [ "${CI_COMMIT_BRANCH}" == "main" ]; then echo "true"; else echo "false"; fi)" | tee -a workflow.env
      echo "IS_RELEASE_BRANCH=$(if [[ "${CI_COMMIT_BRANCH}" =~ ^[0-9]+\.[0-9]+$ ]]; then echo "true"; else echo "false"; fi)" | tee -a workflow.env
      echo "IS_RELEASE=$(if [[ "${CI_COMMIT_TAG}" =~ ^v[0-9]+\.[0-9]+\.[0-9]+(rc[0-9]+)?$ ]]; then echo "true"; else echo "false"; fi)" | tee -a workflow.env
      echo "IS_MERGE_QUEUE=$(if [[ "${CI_COMMIT_BRANCH}" =~ ^gh-readonly-queue/.*$ ]]; then echo "true"; else echo "false"; fi)" | tee -a workflow.env
  artifacts:
    reports:
      dotenv: workflow.env

tests-gen:
  stage: tests
  extends: .testrunner
  id_tokens:
    DDOCTOSTS_ID_TOKEN:
      aud: dd-octo-sts
  script:
    - |
      if [ -z ${GH_TOKEN} ]
      then
        # Use dd-octo-sts to get GitHub token
        export GH_TOKEN=$(dd-octo-sts token --scope DataDog/dd-trace-py --policy gitlab.github-access.read)
      fi
    - scripts/gen_gitlab_config.py --verbose
  needs: [ "pipeline variables" ]
  artifacts:
    paths:
      - .gitlab/tests-gen.yml

run-tests-trigger:
 stage: tests
 needs: [ tests-gen, "pipeline variables" ]
 # Allow the child job to fail if explicitly asked
 rules:
   - if: $RELEASE_ALLOW_TEST_FAILURES == "true"
     allow_failure: true
   - allow_failure: false
 trigger:
   include:
     - artifact: .gitlab/tests-gen.yml
       job: tests-gen
   strategy: depend

# Validate the ast-grep rule's test suite in .sg/tests
"ast-grep rules":
  extends: .testrunner
  stage: tests
  needs: []
  script:
  script:
    - |
      echo -e "\e[0Ksection_start:`date +%s`:sg_test[collapsed=true]\r\e[0KValidate ast-grep rules"
      hatch run lint:sg-test
      echo -e "\e[0Ksection_end:`date +%s`:sg_test\r\e[0K"
    - |
      echo -e "\e[0Ksection_start:`date +%s`:sg_scan[collapsed=true]\r\e[0Kast-grep scan"
      hatch run lint:sg
      echo -e "\e[0Ksection_end:`date +%s`:sg_scan\r\e[0K"

microbenchmarks:
  stage: benchmarks
  needs: [ "download_ddtrace_artifacts" ]
  rules:
    - if: $RELEASE_ALLOW_BENCHMARK_FAILURES == "true"
      allow_failure: true
    - allow_failure: false
  trigger:
    include: .gitlab/benchmarks/microbenchmarks.yml
    strategy: depend
  variables:
    PARENT_PIPELINE_ID: $CI_PIPELINE_ID
    # Disable VPA for benchmarks
    DD_DISABLE_VPA: true

macrobenchmarks:
  stage: benchmarks
  needs: [ "download_ddtrace_artifacts" ]
  trigger:
    include: .gitlab/benchmarks/macrobenchmarks.yml
  variables:
    PARENT_PIPELINE_ID: $CI_PIPELINE_ID
    # Disable VPA for benchmarks
    DD_DISABLE_VPA: true
  allow_failure: true
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - if: $IS_RELEASE == "true"
      when: always
    - when: manual

check_new_flaky_tests:
  stage: tests
  needs: ["run-tests-trigger"]
  extends: .testrunner
  script:
    - export DD_SITE=datadoghq.com
    - export DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.${CI_PROJECT_NAME}.dd-api-key-qualitygate --with-decryption --query "Parameter.Value" --out text)
    - export DD_APP_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.${CI_PROJECT_NAME}.dd-app-key-qualitygate --with-decryption --query "Parameter.Value" --out text)
    - datadog-ci gate evaluate
  rules:
    - if: $IS_MAIN_BRANCH == "true"
      when: never
    - if: $IS_RELEASE == "true"
      when: never
    - if: $IS_RELEASE_BRANCH == "true"
      when: never
    - if: $IS_MERGE_QUEUE == "true"
      when: never
    - when: on_success

pr_name_lint:
  stage: tests
  needs: ["run-tests-trigger"]
  extends: .testrunner
  script:
    - pip install gitlint
    - echo $GH_PR_TITLE | gitlint
  rules:
    - if: "$GH_PR_TITLE" != ""
      when: always

requirements_json_test:
  rules:
    - when: on_success
  variables:
    REQUIREMENTS_BLOCK_JSON_PATH: ".gitlab/requirements_block.json"
    REQUIREMENTS_ALLOW_JSON_PATH: ".gitlab/requirements_allow.json"

package-oci:
  needs: [ download_dependency_wheels, download_ddtrace_artifacts ]

promote-oci-to-prod:
  stage: release
  rules:
    - if: $IS_RELEASE == "true"
      when: on_success
    - when: never
  needs:
    - job: release_pypi_prod
    - job: package-oci
      artifacts: true
    - job: oci-internal-publish
      artifacts: true

promote-oci-to-prod-beta:
  stage: release
  needs:
    - job: package-oci
      artifacts: true
    - job: oci-internal-publish
      artifacts: true

promote-oci-to-staging:
  stage: release
  needs:
    - job: package-oci
      artifacts: true
    - job: oci-internal-publish
      artifacts: true

publish-lib-init-pinned-tags:
  stage: release
  rules:
    - if: $IS_RELEASE == "true"
      when: on_success
    - when: never
  needs:
    - job: release_pypi_prod
    - job: create-multiarch-lib-injection-image
    - job: generate-lib-init-pinned-tag-values
      artifacts: true

configure_system_tests:
  variables:
    SYSTEM_TESTS_SCENARIOS_GROUPS: "simple_onboarding,simple_onboarding_profiling,simple_onboarding_appsec,docker-ssi,lib-injection"

deploy_to_reliability_env:
  needs: []

deploy_to_di_backend:manual:
  stage: shared-pipeline
  rules:
    - when: manual
      allow_failure: true
  trigger:
    project: DataDog/debugger-demos
    branch: main
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME
    UPSTREAM_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA
    UPSTREAM_PIPELINE_ID: $CI_PIPELINE_ID
    UPSTREAM_COMMIT_AUTHOR: $CI_COMMIT_AUTHOR
    UPSTREAM_TAG: $CI_COMMIT_TAG
    UPSTREAM_PACKAGE_JOB: build
