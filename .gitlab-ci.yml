stages:
  - package
  - deploy
  - dogfood
  - benchmarks
  - benchmarks-pr-comment
  - macrobenchmarks

include:
  - remote: https://gitlab-templates.ddbuild.io/apm/packaging.yml
  - local: ".gitlab/benchmarks.yml"
  - local: ".gitlab/macrobenchmarks.yml"
  - local: ".gitlab/dogfood.yml"

variables:
  DOWNSTREAM_BRANCH:
    value: "master"
    description: "Run a specific datadog-reliability-env branch downstream"
  DOWNSTREAM_MBP_BRANCH:
    value: "dd-trace-py"
    description: "Run a specific relenv-microbenchmarking-platform branch downstream"
  PYTHON_PACKAGE_VERSION:
    description: "Version to build for .deb and .rpm. Must be already published in PyPi"

.common: &common
  tags: [ "runner:main", "size:large" ]

package:
  extends: .package
  rules:
  - if: $PYTHON_PACKAGE_VERSION
    when: on_success
  - if: '$CI_COMMIT_TAG =~ /^v.*/'
    when: on_success
  script:
    - ../.gitlab/build-deb-rpm.sh
    - find . -iregex '.*\.\(deb\|rpm\)' -printf '%f\0' | xargs -0 dd-pkg lint

package-arm:
  extends: .package-arm
  rules:
  - if: $PYTHON_PACKAGE_VERSION
    when: on_success
  - if: '$CI_COMMIT_TAG =~ /^v.*/'
    when: on_success
  script:
    - ../.gitlab/build-deb-rpm.sh
    - find . -iregex '.*\.\(deb\|rpm\)' -printf '%f\0' | xargs -0 dd-pkg lint

.release-package:
  stage: deploy
  variables:
    PRODUCT_NAME: auto_inject-python

deploy_to_reliability_env:
  stage: deploy
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: on_success
    - when: manual
      allow_failure: true
  trigger:
    project: DataDog/apm-reliability/datadog-reliability-env
    branch: $DOWNSTREAM_BRANCH
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME
    UPSTREAM_BRANCH: $CI_COMMIT_REF_NAME
    UPSTREAM_COMMIT_SHA: $CI_COMMIT_SHA

deploy_to_di_backend:manual:
  stage: deploy
  rules:
    - when: manual
      allow_failure: true
  trigger:
    project: DataDog/debugger-demos
    branch: main
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME
    UPSTREAM_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA
    UPSTREAM_PIPELINE_ID: $CI_PIPELINE_ID
    UPSTREAM_COMMIT_AUTHOR: $CI_COMMIT_AUTHOR
    UPSTREAM_TAG: $CI_COMMIT_TAG
    UPSTREAM_PACKAGE_JOB: build

generate-lib-init-tag-values:
  tags: ["arch:amd64"]
  image: registry.ddbuild.io/ci/auto_inject/gitlab:current
  stage: deploy
  rules:
    - if: '$POPULATE_CACHE'
      when: never
    # We don't tag prerelease versions
    - if: '$CI_COMMIT_TAG =~ /^v[0-9]+\.[0-9]+\.[0-9]+$/'
      when: on_success
    - when: manual
      allow_failure: true
  variables:
    IMG_DESTINATION_BASE: dd-lib-python-init
  script:
    - ./.gitlab/build-lib-init.sh
  artifacts:
    reports:
      dotenv: build.env

deploy-lib-init-trigger:
  stage: deploy
  # needs the version from the generate-tag-values job
  needs:
    - job: generate-lib-init-tag-values
      artifacts: true
  trigger:
#    project: DataDog/dd-trace-dotnet-gitlab-test # can be used for testing
    project: DataDog/public-images
    branch: main
    strategy: depend
  variables:
    IMG_SOURCES: ghcr.io/datadog/dd-trace-py/dd-lib-python-init:$CI_COMMIT_TAG
    IMG_DESTINATIONS: $IMG_DESTINATIONS
    IMG_SIGNING: "false"
    # Wait 4 hours to trigger the downstream job.
    # This is a work-around since there isn't a way to trigger
    # Gitlab from the Github workflow (build_deploy.yml:upload_pypi).
    #
    # The caveat here is that if there is a failure to build to PyPI and it
    # isn't fixed in the retry period then this job will fail and images will
    # not be published.
    RETRY_DELAY: 14400
    RETRY_COUNT: 3

package-oci:
  stage: package
  extends: .package-oci
  rules:
  - if: $PYTHON_PACKAGE_VERSION
    when: on_success
  - if: '$CI_COMMIT_TAG =~ /^v[0-9]+\.[0-9]+\.[0-9]+(-prerelease)?$/'
    when: manual
    allow_failure: false
  script:
    - ../.gitlab/build-oci.sh
  parallel:
    matrix:
      - ARCH:
        - arm64
        - amd64
